<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <meta name="google-site-verification" content="mtFBoyc2JBmbAuiZSxWCWLl4LFWQ9aON4H31IEK4THI" />

  <!-- Primary Meta Tags -->
  <title>IEEE-754 Floating Point Multiplier | Vedic Mathematics VLSI Design | Krishnarjun Mitra | Jadavpur University
  </title>
  <meta name="title"
    content="IEEE-754 Floating Point Multiplier using Vedic Mathematics - Research by Krishnarjun Mitra">
  <meta name="description"
    content="High-Speed Pipelined IEEE-754 Single-Precision Floating Point Multiplier using Hierarchical Vedic 24×24 Mantissa Architecture. VLSI design research project by Krishnarjun Mitra and Souvik Das at Jadavpur University. Verilog HDL implementation, FPGA optimization, Urdhva-Tiryagbhyam sutra.">
  <meta name="keywords"
    content="IEEE-754, floating point multiplier, Vedic mathematics, Urdhva-Tiryagbhyam, VLSI design, Verilog HDL, FPGA, high-speed multiplier, pipelined architecture, mantissa multiplication, Krishnarjun Mitra, Souvik Das, Jadavpur University, digital design, computer arithmetic, Vedic multiplier, hierarchical multiplier, hardware acceleration, ASIC design, digital signal processing, DSP, binary multiplication, Booth multiplier, Wallace tree, hardware optimization, synthesizable Verilog, RTL design, Vivado, Xilinx, electronics engineering, telecommunication engineering, research paper, academic research, final year project, undergraduate research, Indian university research, Kolkata research, Bengal engineering, semiconductor design, chip design, processor design, arithmetic circuits, combinational logic, sequential logic, pipeline design, throughput optimization, FPGA implementation, hardware description language, digital electronics, embedded systems, microelectronics, nanoelectronics, IC design, integrated circuits, computer architecture, reconfigurable computing, parallel processing, single-precision arithmetic, IEEE standard compliance, floating-point unit, FPU design, exponent calculation, mantissa normalization, special case handling, NaN handling, infinity handling, overflow detection, underflow detection, two-stage pipeline, register transfer level, RTL schematic, functional verification, simulation waveforms, testbench design, Vivado synthesis, FPGA prototyping, Artix-7, Virtex, Kintex, Zynq, logic synthesis, timing analysis, critical path optimization, clock frequency, throughput maximization, latency reduction, resource utilization, LUT optimization, carry propagation, parallel architecture, modular design, hierarchical structure, 3×3 multiplier, 6×6 multiplier, 12×12 multiplier, 24×24 multiplier, ancient mathematics, Sutra-based computation, crosswise multiplication, vertical multiplication, partial product generation, addition tree, carry-save adder, ripple carry adder, fast adder, high-performance computing, scientific computing, numerical methods, fixed-point conversion, denormalized numbers, subnormal handling, rounding modes, round-to-nearest, truncation, guard bits, sticky bits, precision arithmetic, error analysis, hardware-software co-design, SoC integration, system-on-chip, application-specific processor, custom instruction, accelerator design, datapath optimization, control logic, finite state machine, FSM design, behavioral modeling, structural modeling, gate-level simulation, post-synthesis simulation, timing constraints, setup time, hold time, clock domain crossing, metastability, synchronous design, asynchronous logic, power consumption analysis, dynamic power, static power, low-power design, clock gating, power gating, voltage scaling, energy efficiency, green computing, sustainable hardware, academic publication, thesis work, dissertation, engineering project, B.E. project, B.Tech project, M.Tech research, Ph.D. research, conference paper, journal article, peer review, citation index, research impact, innovation in VLSI, novel architecture, performance comparison, benchmark results, industry standard, commercial applications, real-time processing, streaming data, signal processing pipeline, image processing, video codec, machine learning accelerator, AI hardware, deep learning, neural network inference, matrix operations, convolution, multiply-accumulate, MAC unit, dot product, vector processing, SIMD architecture, instruction set architecture, ISA extension, compiler optimization, code generation, verification methodology, assertion-based verification, coverage analysis, formal verification, property checking, equivalence checking, static timing analysis, STA, physical design, place and route, floorplanning, routing congestion, wire delay, interconnect optimization, design for testability, DFT, scan chains, built-in self-test, BIST, manufacturing test, yield optimization, defect tolerance, reliability engineering, fault tolerance, error correction, redundancy, graceful degradation">`
  <meta name="author" content="Krishnarjun Mitra, Souvik Das">
  <meta name="robots" content="index, follow">
  <link rel="canonical" href="https://finalyearproject.vercel.app">

  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="website">
  <meta property="og:url" content="https://finalyearproject.vercel.app">
  <meta property="og:title" content="IEEE-754 Floating Point Multiplier using Vedic Mathematics | VLSI Research">
  <meta property="og:description"
    content="High-performance pipelined floating point multiplier design using ancient Vedic mathematics. Research by Krishnarjun Mitra at Jadavpur University. Complete Verilog HDL implementation with FPGA optimization.">
  <meta property="og:image" content="https://finalyearproject.vercel.app/assets/Jadavpur_University.png">
  <meta property="og:site_name" content="Krishnarjun Mitra - VLSI Research">

  <!-- Twitter -->
  <meta property="twitter:card" content="summary_large_image">
  <meta property="twitter:url" content="https://finalyearproject.vercel.app">
  <meta property="twitter:title" content="IEEE-754 Floating Point Multiplier using Vedic Mathematics">
  <meta property="twitter:description"
    content="High-speed pipelined floating point multiplier research using Vedic mathematics and Verilog HDL. Jadavpur University final year project.">
  <meta property="twitter:image" content="https://finalyearproject.vercel.app/assets/Jadavpur_University.png">

  <!-- Additional SEO Tags -->
  <meta name="classification" content="Research, Academic, VLSI, Electronics Engineering">
  <meta name="coverage" content="Worldwide">
  <meta name="distribution" content="Global">
  <meta name="rating" content="General">
  <meta name="revisit-after" content="7 days">
  <meta name="language" content="English">
  <meta name="geo.region" content="IN-WB">
  <meta name="geo.placename" content="Kolkata, West Bengal, India">
  <meta name="geo.position" content="22.5726;88.3639">
  <meta name="ICBM" content="22.5726, 88.3639">

  <!-- Academic Meta Tags -->
  <meta name="citation_title"
    content="Design and Implementation of a High-Speed Pipelined IEEE-754 Floating Point Multiplier using Hierarchical Vedic 24×24 Mantissa Architecture">
  <meta name="citation_author" content="Mitra, Krishnarjun">
  <meta name="citation_author" content="Das, Souvik">
  <meta name="citation_publication_date" content="2025">
  <meta name="citation_institution" content="Jadavpur University">
  <meta name="citation_department" content="Department of Electronics and Telecommunication Engineering">
  <meta name="citation_keywords"
    content="IEEE-754, Floating Point Multiplier, Pipelining, Vedic Mathematics, Urdhva-Tiryagbhyam, Verilog, FPGA, High-Speed Arithmetic, VLSI">

  <!-- Structured Data (JSON-LD) -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "ScholarlyArticle",
    "headline": "Design and Implementation of a High-Speed Pipelined IEEE-754 Floating Point Multiplier using Hierarchical Vedic 24×24 Mantissa Architecture",
    "author": [
      {
        "@type": "Person",
        "name": "Krishnarjun Mitra",
        "affiliation": {
          "@type": "Organization",
          "name": "Jadavpur University",
          "department": "Department of Electronics and Telecommunication Engineering",
          "address": {
            "@type": "PostalAddress",
            "addressLocality": "Kolkata",
            "addressRegion": "West Bengal",
            "addressCountry": "India"
          }
        }
      },
      {
        "@type": "Person",
        "name": "Souvik Das",
        "affiliation": {
          "@type": "Organization",
          "name": "Jadavpur University"
        }
      }
    ],
    "datePublished": "2025",
    "publisher": {
      "@type": "Organization",
      "name": "Jadavpur University"
    },
    "keywords": "IEEE-754, Floating Point Multiplier, Pipelining, Vedic Mathematics, Urdhva-Tiryagbhyam, Verilog, FPGA, High-Speed Arithmetic, VLSI, Digital Design, Hardware Architecture",
    "abstract": "High-performance floating-point arithmetic is a foundational requirement for modern computing. This research presents the design, implementation, and verification of a high-speed, two-stage pipelined floating-point multiplier compliant with the IEEE-754 single-precision standard using hierarchical Vedic multiplier based on the Urdhva-Tiryagbhyam sutra.",
    "inLanguage": "en",
    "about": [
      "VLSI Design",
      "Digital Electronics",
      "Computer Architecture",
      "Floating Point Arithmetic",
      "Vedic Mathematics",
      "FPGA Design"
    ]
  }
  </script>

  <link rel="icon" type="image/png" href="favicon-small.png">
  <link rel="shortcut icon" type="image/png" href="favicon-small.png">
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link
    href="https://fonts.googleapis.com/css2?family=Merriweather:wght@300;400;700;900&family=Source+Sans+3:wght@300;400;600;700&display=swap"
    rel="stylesheet">
  <link rel="stylesheet" href="style.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/html2pdf.js/0.10.1/html2pdf.bundle.min.js"
    integrity="sha512-GsEyh8GgYfUdw2GFqtZUt8gmfSdJQOnE5n9PpG1GQJzCqJrjVfGqYwIV/pY5Pja/qvp5AYA9YVBus7PAGfQ1HA=="
    crossorigin="anonymous" referrerpolicy="no-referrer"></script>
  <script src="assets/assets.js"></script>
  <script src="app.js" defer></script>
</head>

<body>

  <button id="toc-toggle" class="toc-toggle" aria-controls="toc-drawer" aria-expanded="false"
    aria-label="Toggle table of contents">Contents</button>
  
  <button id="column-toggle" class="column-toggle" aria-label="Toggle column layout" title="Toggle single/double column">
    <svg viewBox="0 0 24 24" width="20" height="20" aria-hidden="true">
      <rect x="3" y="4" width="8" height="16" fill="none" stroke="currentColor" stroke-width="2"/>
      <rect x="13" y="4" width="8" height="16" fill="none" stroke="currentColor" stroke-width="2"/>
    </svg>
  </button>
  
  <aside id="toc-drawer" class="toc-drawer" aria-label="Table of Contents Drawer" aria-hidden="true">
    <button id="toc-close" class="toc-close" aria-label="Hide contents" title="Hide">
      <svg viewBox="0 0 24 24" aria-hidden="true">
        <path d="M15.41 7.41 14 6l-6 6 6 6 1.41-1.41L10.83 12z" />
      </svg>
    </button>
    <nav class="toc" aria-label="Table of Contents">
      <h2>Contents</h2>
      <ol id="toc-list"></ol>
    </nav>
  </aside>

  <div class="container" id="report">

    <div class="title-page">
      <div>
        <h1>Design and Implementation of a High-Speed Pipelined IEEE-754 Floating Point Multiplier using Hierarchical
          Vedic 24×24 Mantissa Architecture</h1>
        <br>
        <h2>A Final Year Project Report</h2>
        <p>Submitted in partial fulfillment of the requirements for the degree of</p>
        <h3>Bachelor of Engineering</h3>
        <p>in</p>
        <h3>Electronics and Telecommunication Engineering</h3>
        <br>
        <div class="authors">
          by<br>
          <b>Krishnarjun Mitra</b><br>
          <b>Souvik Das</b><br>
          (Session 2022–2026)
        </div>
        <br>
        <div class="supervisor">
          Under the supervision of<br>
          <b>Prof. P. Venkateswaran</b>
        </div>
      </div>
      <div class="university-info">
        <div class="logo-placeholder">
          <img src="assets/Jadavpur_University.png" alt="Jadavpur University Logo" />
        </div>
        <h3>Department of Electronics and Telecommunication Engineering</h3>
        <h3>JADAVPUR UNIVERSITY</h3>
        <p>Kolkata, India</p>
        <p>2025</p>
      </div>
    </div>

    <section class="preface">
      <h2>Preface</h2>
      <p>This report documents the conception, design, verification, and analysis of a high-speed pipelined
        IEEE&#x2011;754 single-precision floating point multiplier employing a hierarchical Vedic 24&times;24 mantissa
        architecture. The work was undertaken as part of the Final Year Project requirement at Jadavpur University and
        reflects a synthesis of classic computer arithmetic, modern digital design methodologies, and ancient Vedic
        mathematical principles chosen for their structural regularity and hardware efficiency.</p>
      <p>The project objective was twofold: (1) engineer a logically correct and throughput-optimized multiplier
        suitable for FPGA deployment, and (2) evaluate the viability of recursive Urdhva&#x2011;Tiryagbhyam
        decomposition versus conventional Booth / Wallace techniques in terms of modularity and pipeline friendliness.
        Emphasis was placed on clean, synthesizable Verilog HDL, deterministic handling of IEEE special cases, and
        architectural clarity enabling future extension to double precision and deeper pipelines.</p>
      <p>This Preface provides context for readers approaching the subsequent technical sections. The Literature Review
        situates our design amid contemporary optimization strategies; architectural chapters then detail field
        extraction, special case logic, exponent path, and mantissa multiplication hierarchy. Simulation evidence,
        followed by synthesis discussion, establishes functional soundness and practical feasibility.</p>
      <ul class="author-bios">
        <li><strong>Krishnarjun Mitra</strong> — Primary architect and implementer of the pipelined multiplier,
          hierarchical Vedic modules, verification environment, and documentation integration. Interests include
          high‑performance arithmetic circuits, FPGA acceleration, and algorithm-hardware co‑design.</li>
        <li><strong>Souvik Das</strong> — Contributor in literature analysis, comparative methodology discussions, and
          manuscript review. Academic interests span digital signal processing, numerical methods, and efficient
          datapath structures.</li>
      </ul>
    </section>

    <!-- Print-only QR Code Section -->
    <section class="print-qr-section">
      <div class="qr-code">
        <img src="https://api.qrserver.com/v1/create-qr-code/?size=200x200&data=https://juetce-finalyearproject.vercel.app"
          alt="QR Code to Project Website">
      </div>
      <div class="qr-details">
        <h3>Online Availability</h3>
        <p>The complete project documentation, is available at the following web address:</p>
        <p class="site-url">https://juetce-finalyearproject.vercel.app</p>
        <p class="qr-footer">Scan the QR code or visit the URL to access the digital version of this research work.</p>
      </div>
    </section>

    <div class="preface-separator"></div>

    <!-- Print-only Table of Contents -->
    <section class="print-toc">
      <h2>Table of Contents</h2>
      <ol>
        <li>
          <div class="toc-entry"><span class="toc-title">1. Introduction</span><span class="toc-dots"></span><span
              class="toc-page">5</span></div>
        </li>
        <li>
          <div class="toc-entry"><span class="toc-title">2. Literature Review</span><span class="toc-dots"></span><span
              class="toc-page">6</span></div>
        </li>
        <li>
          <div class="toc-entry"><span class="toc-title">3. IEEE-754 Floating Point Format</span><span
              class="toc-dots"></span><span class="toc-page">6</span></div>
        </li>
        <li>
          <div class="toc-entry"><span class="toc-title">4. Proposed Architecture</span><span
              class="toc-dots"></span><span class="toc-page">7</span></div>
        </li>
        <li>
          <div class="toc-entry"><span class="toc-title">5. Pipeline Architecture</span><span
              class="toc-dots"></span><span class="toc-page">7</span></div>
        </li>
        <li>
          <div class="toc-entry"><span class="toc-title">6. Vedic Mantissa Multiplier</span><span
              class="toc-dots"></span><span class="toc-page">9</span></div>
        </li>
        <li>
          <div class="toc-entry"><span class="toc-title">7. Implementation in Verilog HDL</span><span
              class="toc-dots"></span><span class="toc-page">11</span></div>
        </li>
        <li>
          <div class="toc-entry"><span class="toc-title">8. Schematic Overview</span><span class="toc-dots"></span><span
              class="toc-page">13</span></div>
        </li>
        <li>
          <div class="toc-entry"><span class="toc-title">9. Simulation and Waveform Analysis</span><span
              class="toc-dots"></span><span class="toc-page">14</span></div>
        </li>
        <li>
          <div class="toc-entry"><span class="toc-title">10. Results</span><span class="toc-dots"></span><span
              class="toc-page">15</span></div>
        </li>
        <li>
          <div class="toc-entry"><span class="toc-title">11. Conclusion</span><span class="toc-dots"></span><span
              class="toc-page">15</span></div>
        </li>
        <li>
          <div class="toc-entry"><span class="toc-title">12. Future Scope</span><span class="toc-dots"></span><span
              class="toc-page">16</span></div>
        </li>
        <li>
          <div class="toc-entry"><span class="toc-title">13. Acknowledgment</span><span class="toc-dots"></span><span
              class="toc-page">16</span></div>
        </li>
        <li>
          <div class="toc-entry"><span class="toc-title">14. Author Contributions</span><span
              class="toc-dots"></span><span class="toc-page">16</span></div>
        </li>
        <li>
          <div class="toc-entry"><span class="toc-title">15. References</span><span class="toc-dots"></span><span
              class="toc-page">17</span></div>
        </li>
      </ol>
    </section>

    <div class="main-content">

      <div class="abstract">
        <h3>Abstract</h3>
        <p>High-performance floating-point arithmetic is a foundational requirement for modern computing, powering
          fields from Digital Signal Processing (DSP) to artificial intelligence and scientific computing. The
          floating-point multiplier, in particular, is a critical component that often dictates overall system
          performance and resource utilization. This project presents the design, implementation, and verification of a
          high-speed, two-stage pipelined floating-point multiplier compliant with the IEEE-754 single-precision
          standard. The core innovation of this design lies in the implementation of the 24-bit mantissa multiplication
          stage using a hierarchical Vedic multiplier based on the Urdhva-Tiryagbhyam sutra. This ancient mathematical
          technique is leveraged for its inherent parallelism and structural regularity, making it highly suitable for
          VLSI and FPGA implementation. The architecture is described in synthesizable Verilog HDL and features a
          recursive 3×3 → 6×6 → 12×12 → 24×24 multiplier hierarchy. The pipelined design enhances throughput, while
          dedicated logic ensures correct handling of special cases, including Zero, Infinity (Inf), and Not-a-Number
          (NaN), as well as overflow and underflow conditions. The design was functionally verified through extensive
          simulation in the Vivado Design Suite, demonstrating its logical correctness and adherence to the IEEE-754
          standard.</p>
      </div>

      <div class="keywords">
        <h3>Keywords</h3>
        <p>IEEE-754 Standard; Floating-Point Arithmetic; Single-Precision Multiplier; Pipelined Architecture; Vedic Mathematics; Urdhva-Tiryagbhyam Sutra; Hardware Description Language (HDL); Verilog RTL; Field-Programmable Gate Array (FPGA); Application-Specific Integrated Circuit (ASIC); High-Speed Arithmetic; Very Large Scale Integration (VLSI); Digital Signal Processing (DSP); Special Case Handling; NaN Propagation; Infinity Arithmetic; Mantissa Multiplication; Exponent Processing; Hierarchical Multiplier Design; Carry-Save Addition; Partial Product Reduction; Synthesis Optimization; Timing Closure; Throughput Maximization; Latency Minimization; Register-Transfer Level (RTL) Design; Vivado Design Suite; Functional Verification; Simulation Waveforms; IEEE Standard Compliance; Overflow/Underflow Detection; Normalization Logic; Denormalized Number Handling.</p>
      </div>

      <h3>1. Introduction</h3>
      <p>In the last few decades, the demand for high-performance computing has grown exponentially. Applications in
        digital signal processing (DSP), graphics rendering, scientific simulation, and the burgeoning field of machine
        learning rely heavily on complex mathematical operations [1]. At the heart of these operations is floating-point
        (FP) arithmetic, which provides a wide dynamic range and high precision for representing real numbers [2].</p>
      <p>Within the suite of FP operations, floating-point multiplication is a fundamental and frequently executed
        instruction. However, it is also one of the most resource-intensive and time-consuming, often forming the
        critical path in a processor's datapath [3]. The complexity of an FP multiplier stems from its three main tasks:
        calculating the sign, adding the exponents, and most significantly multiplying the large mantissas.</p>
      <p>Traditional approaches to mantissa multiplication, such as the Booth encoding or array multipliers, have been
        highly optimized. However, they can still suffer from complex routing, large area, and significant propagation
        delays. This has spurred research into alternative multiplication algorithms.</p>
      <p>This project explores one such alternative: the application of ancient Vedic mathematics to modern digital
        design. Specifically, we utilize the <b>Urdhva-Tiryagbhyam</b> (vertically and crosswise) sutra, a technique
        known for its parallel and regular structure [4]. The algorithm breaks down a large multiplication into smaller,
        independent cross-products, which are then summed. This "divide and conquer" methodology is inherently parallel
        and maps efficiently onto the hardware structure of an FPGA.</p>
      <p>To further enhance performance, our design incorporates a <b>two-stage pipeline</b>. While any combinational
        multiplier has a significant propagation delay, pipelining allows us to increase the clock frequency and,
        consequently, the data throughput. By registering the intermediate results, we can process one multiplication
        per clock cycle, albeit with an initial two-cycle latency.</p>
      <p>This report details the design and implementation of a complete 32-bit single-precision floating-point
        multiplier. It combines the speed of a pipelined architecture with the structural efficiency of a
        hierarchically-designed 24×24 Vedic mantissa multiplier. The entire system is implemented in Verilog HDL,
        verified in Vivado, and handles all special cases (Zero, Inf, NaN) as specified by the IEEE-754 standard.</p>
      <p>The following sections cover the relevant literature, the IEEE-754 standard fundamentals, and the detailed architecture of our proposed multiplier.</p>

      <h3>2. Literature Review</h3>
      <p>The optimization of floating-point multipliers is a well-established field of research. Our work builds upon a
        significant body of existing literature while exploring a specific combination of techniques.</p>
      <p><b>Havaldar and Gurumurthy [4]</b> provide a foundational work by also proposing a design for an IEEE-754
        floating-point multiplier using Vedic mathematics. They highlight the Urdhva-Tiryagbhyam sutra's suitability for
        reducing hardware complexity and path delay compared to conventional array or Booth multipliers. Our project
        extends this concept by implementing a deeply hierarchical 3×3 → 6×6 → 12×12 → 24×24 structure for the mantissa
        and integrating it into a formal two-stage pipeline to maximize throughput, a specific architectural detail that
        builds upon their general concept.</p>
      <p>In contrast, <b>Bai et al. [3]</b> focus on a different optimization route, employing an expanded Booth-Wallace
        algorithm. The Wallace tree is a highly optimized method for summing partial products, and Booth encoding is the
        industry standard for reducing their number. This approach represents the "traditional" high-performance design.
        Our project intentionally diverges from this path to explore the Vedic algorithm as a viable alternative,
        comparing its design simplicity and structural regularity against the optimized but more complex Booth-Wallace
        method.</p>
      <p><b>Ghabeli [2]</b> introduces an advanced technique called Multi-Path Mantissa Processing (MPM). This design
        uses adaptive data timing channels, where the computation path's delay varies based on the input data, such as
        detecting leading zeros in the mantissa. This is an alternative method for accelerating the "average-case"
        performance. Our design, instead, focuses on optimizing the "worst-case" delay and maximizing throughput for all
        inputs via a fixed two-stage pipeline.</p>
      <p>Finally, <b>Hemant and Raghuwanshi [1]</b> analyze the impact of different high-speed <i>adders</i> (e.g.,
        Carry Choose Adder) on the exponent calculation path of an FP multiplier. Their work underscores that every part
        of the FPU is a target for optimization. While their focus is on the 8-bit/11-bit exponent addition, our
        project's primary contribution is the optimization of the 24-bit mantissa multiplication path, which is the
        dominant component in terms of complexity and delay.</p>
      <p>In summary, the literature shows diverse approaches to FPU optimization, from adders [1] to Booth-Wallace trees
        [3] and adaptive paths [2]. Our work contributes to this field by focusing on the synthesis of two powerful
        concepts: a deep pipeline for throughput and the Urdhva-Tiryagbhyam algorithm for an efficient, parallel, and
        regular mantissa multiplier [4].</p>

      <h3>3. IEEE-754 Floating Point Format</h3>
      <p>The IEEE-754 standard defines the representation of floating-point numbers in binary. This project implements
        the 32-bit single-precision format.</p>
      <p>A 32-bit FP number is partitioned into three fields:</p>
      <ul>
        <li><b>Sign (S):</b> 1 bit (Bit 31). `0` for positive, `1` for negative.</li>
        <li><b>Exponent (E):</b> 8 bits (Bits 30-23). Stored with a bias of 127. The actual exponent is `E - 127`.</li>
        <li><b>Fraction (F):</b> 23 bits (Bits 22-0). Represents the fractional part of the mantissa.</li>
      </ul>

      <figure class="diagram" id="diagram-ieee754-format">
        <img src="assets/ieee754_format.png"
          alt="IEEE-754 32-bit floating point format showing sign, exponent, and fraction fields"
          onerror="this.parentElement.innerHTML='<div class=\'placeholder\'>[Figure 1: IEEE-754 Single-Precision Format - Image: assets/ieee754_format.png]</div>'">
        <figcaption><strong>Fig. 1:</strong> IEEE-754 Single-Precision Format</figcaption>
      </figure>

      <p>For <i>normalized</i> numbers, the standard assumes a hidden "1" before the binary point of the fraction. Thus,
        the complete mantissa is `1.F`.</p>
      <p>The value (V) of a normalized number is given by:</p>
      <p class="formula"><i>V = (-1)<sup>S</sup> × 2<sup>(E-127)</sup> × (1.F)</i></p>

      <p>The standard also defines several special cases, which our design must handle:</p>
      <ul>
        <li><b>Zero:</b> When `E = 0` (all zeros) and `F = 0` (all zeros). The sign bit can be 0 or 1, representing +0
          and -0. Zero values require special handling in multiplication to ensure correct propagation: any number multiplied by zero must yield zero, preserving the appropriate sign based on the XOR of input signs.</li>
        <li><b>Infinity (Inf):</b> When `E = 255` (all ones) and `F = 0` (all zeros). This represents overflow or
          division by zero. In multiplication, infinity behaves such that Inf × (non-zero finite) = Inf, Inf × Inf = Inf, but Inf × 0 produces NaN, as this operation is mathematically indeterminate. Proper detection and priority handling of infinity cases ensures compliance with IEEE-754 semantics.</li>
        <li><b>Not-a-Number (NaN):</b> When `E = 255` (all ones) and `F ≠ 0` (non-zero). This represents the result of
          invalid operations, such as `0/0` or `Inf × 0`. NaN has the highest priority in our exception handling hierarchy: any operation involving a NaN input must propagate NaN to the output, typically as a canonical quiet NaN (sign=0, E=255, F=0x400000). This ensures that computational errors are flagged and do not silently corrupt subsequent calculations.</li>
        <li><b>Denormalized Numbers:</b> When `E = 0` and `F ≠ 0`. These represent very small numbers (subnormals) near the underflow threshold, with an implicit leading zero instead of one. Our design treats
          denormalized inputs as zero, which is a common simplification in high-speed multipliers. This trade-off sacrifices precision for very small magnitudes in exchange for reduced hardware complexity and improved timing performance, as full denormal support would require additional normalization stages and leading-zero detection circuits.</li>
      </ul>

      <h3>4. Proposed Architecture</h3>
      <p>The proposed floating-point multiplier implements the multiplication of two 32-bit IEEE-754 numbers, `A` and
        `B`, to produce a 32-bit result, `Y`.</p>

      <figure class="diagram" id="diagram-proposed-architecture">
        <img src="assets/proposed_architecture.png"
          alt="Block diagram of the proposed floating point multiplier architecture"
          onerror="this.parentElement.innerHTML='<div class=\'placeholder\'>[Figure 2: Proposed Floating Point Multiplier Architecture - Image: assets/proposed_architecture.png]</div>'">
        <figcaption><strong>Fig. 2:</strong> Proposed Floating Point Multiplier Architecture</figcaption>
      </figure>

      <p>The overall architecture is partitioned into several key functional units, which are mapped into a two-stage
        pipeline:</p>
      <ol>
        <li><b>Field Extractor:</b> In Stage 1, the 32-bit inputs `A` and `B` are deconstructed into their respective
          Sign (`S_a`, `S_b`), Exponent (`E_a`, `E_b`), and Fraction (`F_a`, `F_b`) fields.</li>
        <li><b>Special Case Detector:</b> Parallel logic checks the exponent and fraction fields of both inputs to flag
          any Zero, Infinity, or NaN conditions.</li>
        <li><b>Sign Calculator:</b> The resultant sign (`S_y`) is computed by a simple XOR of the input signs: `S_y =
          S_a ⊕ S_b`.</li>
        <li><b>Exponent Adder:</b> This unit calculates the new exponent. It sums the two 8-bit exponents and subtracts
          the bias (127): `E_y = E_a + E_b - 127`. This raw sum is later adjusted during normalization.</li>
        <li><b>Vedic Mantissa Multiplier:</b> This is the core of the design. It takes the 23-bit fractions `F_a` and
          `F_b`, prepends the hidden "1" to create two 24-bit mantissas (`M_a = {1, F_a}` and `M_b = {1, F_b}`), and
          multiplies them. This is done by the `vedic24x24` module, which produces a 48-bit product `P_m`.</li>
        <li><b>Normalizer & Selector (Stage 2):</b> This unit takes the intermediate results (S_y, E_y, P_m) and the
          special case flags from Stage 1. It performs two main tasks:
          <ul>
            <li><b>Priority Selection:</b> It checks the special case flags. If a NaN, Inf, or Zero condition is met, it
              forces the output to the correct IEEE-754 representation for that case (e.g., `32'h7FC00000` for NaN).
            </li>
            <li><b>Normalization:</b> For a normal multiplication, the 48-bit product `P_m` must be normalized. The
              product `M_a × M_b` will be between 1.0 and ~4.0. If the MSB of the product (`P_m[47]`) is `1`, the
              product is in the range [2.0, 4.0). The mantissa is taken from `P_m[46:24]` and the exponent `E_y` is
              incremented by 1. If the MSB (`P_m[47]`) is `0`, the product is in the range [1.0, 2.0). The mantissa is
              taken from `P_m[45:23]` and the exponent is unchanged.</li>
            <li>It also checks for <b>Overflow</b> (final exponent > 254) and <b>Underflow</b> (final exponent <= 0),
                setting the result to Inf or Zero, respectively.</li>
          </ul>
        </li>
        <li><b>Output Assembler:</b> The final selected Sign, Exponent, and Mantissa are concatenated to form the 32-bit
          output `Y`.</li>
      </ol>

      <h3>5. Pipeline Architecture</h3>
      <p>To achieve high throughput, the design is partitioned into a two-stage pipeline, separated by a bank of
        registers. This architectural decision is fundamental to maximizing computational efficiency and enabling the multiplier to sustain a throughput of one operation per clock cycle. Pipelining breaks the critical path—the longest combinational delay between two flip-flops—into shorter segments, thereby allowing higher operating frequencies without sacrificing correctness. By inserting pipeline registers between Stage 1 and Stage 2, the design effectively overlaps the execution of multiple floating-point multiplications: while Stage 2 is finalizing the result for operation <i>n</i>, Stage 1 is concurrently processing the mantissa multiplication and exponent addition for operation <i>n+1</i>. This spatial and temporal parallelism is the cornerstone of high-performance arithmetic units in modern processors and FPGAs.</p>
      <p>The `valid_in` and `valid_out` handshake signals provide robust flow control and synchronization. When an upstream module (such as a memory controller or another functional unit) has valid data ready, it asserts `valid_in` for one clock cycle while presenting operands `a` and `b`. The input registers (`a_r`, `b_r`, `valid_r`) capture this data on the rising edge of `clk`. The `valid_in` signal propagates through the pipeline stages as `valid_r` and `valid_stage1`, ultimately emerging as `valid_out` two clock cycles later, synchronized with the computed result `y`. This handshake protocol ensures that downstream logic only consumes results when they are guaranteed to be correct, preventing race conditions and enabling seamless integration into larger, complex System-on-Chip (SoC) designs. The pipeline latency is deterministically two clock cycles, and once the pipeline is filled, one new result is produced every clock cycle, achieving optimal throughput for sustained workloads such as vector dot products, matrix multiplications, or real-time DSP filtering operations.</p>

      <figure class="diagram" id="diagram-pipeline-architecture">
        <img src="assets/pipeline_architecture.png" alt="Pipeline architecture diagram showing Stage 1 and Stage 2"
          onerror="this.parentElement.innerHTML='<div class=\'placeholder\'>[Figure 3: Two-Stage Pipeline Architecture - Image: assets/pipeline_architecture.png]</div>'">
        <figcaption><strong>Fig. 3:</strong> Two-Stage Pipeline Architecture</figcaption>
      </figure>

      <h4>Stage 1: Multiply and Add</h4>
      <p>This stage contains the most computationally intensive logic. It performs the parallel multiplication of the
        mantissas and the addition of the exponents.</p>
      <ul>
        <li><b>Inputs:</b> `clk`, `rstn`, `a`, `b`, `valid_in`.</li>
        <li><b>Registers:</b> `a_r`, `b_r`, `valid_r`.</li>
        <li><b>Combinational Logic:</b>
          <ol>
            <li>Inputs `a` and `b` are latched into `a_r` and `b_r`.</li>
            <li>Fields are extracted from `a_r` and `b_r`.</li>
            <li>All special case flags (`a_is_zero`, `b_is_inf`, `a_is_nan`, etc.) are computed.</li>
            <li>The 24-bit mantissas (`man_a`, `man_b`) are formed.</li>
            <li>The `vedic24x24` module runs, producing the 48-bit `man_prod`.</li>
            <li>The exponents are added (`exp_sum = exp_a + exp_b`).</li>
            <li>The preliminary normalization logic (checking `msb_prod`, selecting `mant_trunc`, and calculating
              `exp_unbiased_signed`) is performed.</li>
          </ol>
        </li>
        <li><b>Pipeline Registers (Output):</b> At the next positive clock edge, all intermediate results are latched
          into the Stage 2 registers:
          <ul>
            <li>`mant_r` (23 bits)</li>
            <li>`expu_r` (10 bits)</li>
            <li>`sign_r_r` (1 bit)</li>
            <li>All special case flags (e.g., `a_zero_r`, `b_nan_r`)</li>
            <li>`valid_stage1` (from `valid_r`)</li>
          </ul>
        </li>
      </ul>

      <h4>Stage 2: Normalize, Select, and Finalize</h4>
      <p>This stage operates on the stable outputs from the Stage 1 pipeline registers. It is a large priority-based
        selection logic.</p>
      <ul>
        <li><b>Inputs:</b> All registered signals from Stage 1.</li>
        <li><b>Combinational Logic (`always @*` block):</b>
          <ol>
            <li>A priority multiplexer selects the final output `y_next`.</li>
            <li><b>Highest Priority (NaN):</b> If `a_nan_r` or `b_nan_r` is true, or if `Inf * 0`, `y_next` is set to
              the quiet NaN representation (`32'h7FC00000`).</li>
            <li><b>Next Priority (Infinity):</b> If `a_inf_r` or `b_inf_r` is true (and not a NaN case), `y_next` is set
              to Infinity (`{sign_r_r, 8'hFF, 23'd0}`).</li>
            <li><b>Next Priority (Zero):</b> If `a_zero_r` or `b_zero_r` is true (and not a NaN case), `y_next` is set
              to Zero (`{sign_r_r, 8'd0, 23'd0}`).</li>
            <li><b>Lowest Priority (Normal Calculation):</b>
              <ul>
                <li>The registered exponent `expu_r` (now `exp_s`) is checked.</li>
                <li>If `exp_s > 254` (Overflow), `y_next` is set to Inf.</li>
                <li>If `exp_s <= 0` (Underflow), `y_next` is set to Zero.</li>
                <li>Otherwise, the final result is assembled: `y_next = {sign_r_r, exp_s[7:0], mant_r}`.</li>
              </ul>
            </li>
          </ol>
        </li>
        <li><b>Output Registers:</b> The final `y_next` and `valid_next` are registered at the module's output ports,
          `y` and `valid_out`, to ensure a clean, synchronous output.</li>
      </ul>

      <h3>6. Vedic Mantissa Multiplier</h3>
      <p>The core of our design's performance and structural regularity comes from the 24×24 mantissa multiplier, which
        is built using the principles of Vedic mathematics. Vedic mathematics, derived from ancient Indian scriptures (the Vedas), encompasses a collection of mathematical techniques and sutras (aphorisms) that provide elegant, efficient algorithms for arithmetic operations. Among these, the Urdhva-Tiryagbhyam sutra stands out for its applicability to digital multiplication, offering inherent parallelism that aligns perfectly with modern hardware design paradigms.</p>

      <h4>Urdhva-Tiryagbhyam (Vertically & Crosswise)</h4>
      <p>The Urdhva-Tiryagbhyam sutra, translating to "vertically and crosswise," provides a general "divide and conquer" algorithm for multiplication that is fundamentally different from traditional shift-and-add or Booth encoding methods. The key insight of this sutra is that multiplication can be decomposed into independent, parallel cross-multiplication operations, which are then combined through summation. This property directly translates to hardware efficiency: independent operations can be computed concurrently without complex control logic, and the regular structure simplifies both design and verification.</p>
      <p>To multiply two N-bit numbers using this sutra, we split them into two N/2-bit halves:</p>
      <ul>
        <li>`A = A_hi | A_lo` (where `A_hi` represents the upper N/2 bits and `A_lo` the lower N/2 bits)</li>
        <li>`B = B_hi | B_lo` (similarly partitioned)</li>
      </ul>
      <p>The product `P = A × B` is then calculated in four parallel, independent steps. These four partial products correspond to the cross-multiplication terms that emerge from the algebraic expansion:</p>
      <ol>
        <li>`P0 = A_lo × B_lo` (low × low) – represents the least significant portion of the product</li>
        <li>`P1 = A_lo × B_hi` (low × high) – cross-term contributing to middle bits</li>
        <li>`P2 = A_hi × B_lo` (high × low) – another cross-term for middle bits</li>
        <li>`P3 = A_hi × B_hi` (high × high) – represents the most significant portion</li>
      </ol>
      <p>These four partial products are then summed with appropriate bit-shifts to produce the final 2N-bit result. The shifting accounts for the positional weight of each partial product in the final result:</p>
      <p class="formula"><i>P = (P3 &lt;&lt; N) + ((P1 + P2) &lt;&lt; (N/2)) + P0</i></p>
      <p>This formulation reveals a critical advantage: all four partial products (`P0` through `P3`) can be computed simultaneously, as they have no data dependencies on each other. In hardware, this translates to four parallel multiplier instances operating concurrently, drastically reducing latency compared to sequential methods. Furthermore, the addition of these shifted partial products can be implemented using efficient multi-operand adder structures such as carry-save adders or Wallace/Dadda trees, which synthesis tools can automatically optimize.</p>

      <h4>Hierarchical Architecture</h4>
      <p>Our design applies the Urdhva-Tiryagbhyam principle recursively to build the 24×24 multiplier, creating a deeply hierarchical structure that maximizes regularity and design reuse. This recursive decomposition is conceptually elegant: each level of the hierarchy solves the same problem (multiplication) at a smaller scale, using identical algorithmic principles. From a hardware perspective, this yields a highly modular design where each level is independently verifiable, and the overall structure exhibits predictable timing and resource utilization characteristics.</p>
      <p>The hierarchical structure consists of four distinct levels, each doubling the operand size of the previous level. The recursive nature ensures that design effort is minimized—once a single level is verified, the higher levels are constructed simply by instantiation and interconnection, with minimal additional logic.</p>

      <!-- <figure class="diagram" id="diagram-vedic-hierarchy">
        <img src="assets/vedic_hierarchy.png" alt="Hierarchical structure of Vedic multiplier from 3x3 to 24x24"
          onerror="this.parentElement.innerHTML='<div class=\'placeholder\'>[Figure 4: Vedic Multiplier Hierarchy - Image: assets/vedic_hierarchy.png]</div>'">
        <figcaption><strong>Fig. 4:</strong> Vedic Multiplier Hierarchy</figcaption>
      </figure> -->

      <ol>
        <li><b>Base Case: 3×3 Multiplier (`vedic3x3`)</b><br>This is the fundamental, atomic building block of the entire hierarchy. It takes two 3-bit unsigned inputs and generates a 6-bit product using purely combinational logic. At this scale, the Urdhva-Tiryagbhyam method can be implemented directly using bitwise AND gates to generate partial products, followed by a small network of half-adders and full-adders to sum them. Alternatively, for simplicity and to leverage synthesis tool optimizations, the module can use a direct multiplication operator (`p = a * b`), allowing the synthesis tool to map it to the most efficient available hardware primitives (LUTs, dedicated DSP slices, etc.). This base case terminates the recursion and represents the smallest indivisible multiplication unit. Its simplicity ensures minimal delay and area, which is critical since this module will be instantiated hundreds of times in the complete 24×24 structure.</li>
        
        <li><b>6×6 Multiplier (`vedic6x6`)</b><br>This module is constructed from four `vedic3x3` instances, representing the first level of hierarchical composition. It partitions the 6-bit inputs `a` and `b` into 3-bit high and low halves: `a[5:3]` (high), `a[2:0]` (low), and similarly for `b`. Following the Urdhva-Tiryagbhyam formula, it computes four 6-bit partial products by invoking `vedic3x3` for each combination: `p0 = a_lo × b_lo`, `p1 = a_lo × b_hi`, `p2 = a_hi × b_lo`, `p3 = a_hi × b_hi`. These partial products are then aligned and summed with 3-bit and 6-bit left shifts to produce the final 12-bit result: `p = {p3, 6'b0} + {3'b0, p2, 3'b0} + {3'b0, p1, 3'b0} + {6'b0, p0}`. The adder network at this level is relatively small (combining four 12-bit terms), and synthesis tools typically implement this using carry-lookahead or carry-select adders for optimal speed.</li>
        
        <li><b>12×12 Multiplier (`vedic12x12`)</b><br>Following the same recursive pattern, this module uses four `vedic6x6` instances. It splits the 12-bit inputs into 6-bit high and low halves (`a[11:6]` and `a[5:0]`, respectively, and similarly for `b`). The four `vedic6x6` multipliers compute 12-bit partial products, which are then shifted by 6 bits and 12 bits and summed to produce the final 24-bit result. At this hierarchy level, the adder network becomes more complex, combining four 24-bit operands. However, the regular structure allows synthesis tools to generate optimized adder trees, and the modular nature simplifies timing analysis—critical path delays can be calculated recursively from lower levels. The `vedic12x12` module serves as the intermediate layer that bridges the gap between small-scale (6×6) and large-scale (24×24) multipliers.</li>
        
        <li><b>24×24 Multiplier (`vedic24x24`)</b><br>This is the top-level Vedic multiplier module used by the floating-point unit. It instantiates four `vedic12x12` multipliers, representing the final and largest level of the hierarchy. The 24-bit mantissa operands (which include the implicit leading-one bit of the IEEE-754 format) are split into 12-bit high and low halves. The four `vedic12x12` instances compute four 24-bit partial products: `p0` (low×low), `p1` (low×high), `p2` (high×low), and `p3` (high×high). These are shifted by 12 bits and 24 bits and summed to produce the final 48-bit product. The summation is performed using a simple but efficient four-operand adder tree. In hardware, this is typically implemented as a two-level carry-save adder (CSA) structure: the first level reduces the four 48-bit operands to two (sum and carry), and the second level uses a fast carry-propagate adder (CPA) to produce the final result. Synthesis tools automatically recognize this pattern and optimize it for the target FPGA or ASIC technology, often utilizing dedicated fast-carry chains or DSP blocks. The 48-bit product output feeds directly into the normalization logic in the floating-point pipeline, where the MSB is checked to determine whether a right-shift normalization is required.</li>
      </ol>
      
      <p>This hierarchical structure is highly regular and exhibits several key advantages for FPGA and ASIC implementation. <b>Regularity:</b> Each level follows an identical structural pattern—split inputs, instantiate four sub-multipliers, shift and sum partial products—making the design easy to understand, verify, and debug. <b>Modularity:</b> Each hierarchy level is an independent, self-contained module with well-defined interfaces, enabling parallel development and unit testing. <b>Scalability:</b> The recursive nature means the design can be easily extended to larger operand sizes (e.g., 48×48 for double-precision) by adding one more hierarchy level. <b>Verification:</b> Each level can be verified independently using directed or random test vectors; once the base case (`vedic3x3`) is proven correct, higher levels inherit correctness through composition. <b>Physical Layout and Routing:</b> The hierarchical structure simplifies FPGA place-and-route algorithms. The regular, tree-like topology reduces routing congestion and wire delays, as connections between hierarchy levels are localized and predictable. This results in better timing closure and higher maximum operating frequencies compared to irregular, flat multiplier structures. Additionally, the balanced tree depth (log₄(24) ≈ 2.3 levels) ensures that signal paths from inputs to outputs traverse a uniform number of logic stages, minimizing clock skew and simplifying timing constraints.</p>

      <h3 class="page-break-before">7. Implementation in Verilog HDL</h3>
      <p>The entire design was implemented in synthesizable Verilog HDL, following a modular, hierarchical approach. The implementation is structured across multiple source files, each representing a distinct functional unit, enabling independent verification and promoting design reusability. All modules adhere to industry-standard coding practices, ensuring portability across synthesis and simulation tools.</p>
      
      <h4>7.1 Top-Level Module: `fp_mul_pipelined.v`</h4>
      <p>The `fp_mul_pipelined` module serves as the top-level entity, orchestrating the entire floating-point multiplication operation. It implements a robust two-stage pipelined architecture designed to maximize throughput while maintaining functional correctness across all IEEE-754 special cases.</p>
      <p><b>Port Interface:</b></p>
      <ul>
        <li><b>Input:</b> `clk` (clock), `rstn` (active-low asynchronous reset), `a[31:0]` and `b[31:0]` (32-bit IEEE-754 operands), `valid_in` (input data valid signal)</li>
        <li><b>Output:</b> `y[31:0]` (32-bit IEEE-754 result), `valid_out` (output data valid signal)</li>
      </ul>
      <p><b>Pipeline Architecture:</b></p>
      <ul>
        <li><b>Stage 0 (Input Capture):</b> Registers `a_r`, `b_r`, and `valid_r` capture input operands on every clock cycle, providing synchronization and timing isolation from upstream logic.</li>
        <li><b>Stage 1 (Mantissa Multiplication & Exponent Addition):</b> The captured operands are decomposed into sign, exponent (8 bits), and fraction (23 bits). Implicit leading-one bits are restored for normalized numbers, forming 24-bit mantissas (`man_a`, `man_b`). The `vedic24x24` multiplier computes the 48-bit product (`man_prod`). Concurrently, exponents are summed (`exp_sum`) and special case flags (zero, infinity, NaN) are evaluated. Normalization logic determines whether the MSB of the product (`man_prod[47]`) is set; if so, the mantissa is right-shifted by one position, and the exponent is incremented accordingly. The normalized 23-bit mantissa (`mant_trunc`), adjusted exponent (`exp_unbiased_signed`), special case flags, and result sign are registered at the end of Stage 1.</li>
        <li><b>Stage 2 (Result Finalization & Exception Handling):</b> Combinational logic evaluates the registered flags in priority order: NaN (highest priority), Infinity, Zero, followed by normal case processing. For normal results, the signed exponent is checked for overflow (>254 → +Inf) and underflow (≤0 → Zero). Valid results are formatted as IEEE-754 single-precision numbers. The final output and `valid_out` flag are registered, ensuring clean, glitch-free outputs.</li>
      </ul>
      <p><b>Special Case Handling:</b> The module implements complete IEEE-754 exception semantics: any operation involving NaN propagates a quiet NaN (`0x7FC00000`). Infinity multiplied by zero produces NaN. Infinity multiplied by any non-zero finite number produces signed infinity. Any multiplication with zero (except NaN or 0×Inf) produces signed zero. Overflow conditions produce signed infinity, and underflow conditions produce signed zero.</p>
      <p><b>Key Design Features:</b> All internal registers are protected by the asynchronous active-low reset (`rstn`), ensuring deterministic startup behavior. The `valid_in`/`valid_out` handshake protocol allows seamless integration with upstream and downstream pipeline stages, enabling backpressure and flow control in complex SoC designs. The design is fully synthesizable and optimized for FPGA and ASIC targets.</p>

      <h4>7.2 24-bit Vedic Multiplier: `vedic24x24.v`</h4>
      <p>The `vedic24x24` module implements the top level of the Vedic multiplication hierarchy, computing the unsigned product of two 24-bit operands to produce a 48-bit result. This multiplication is critical for IEEE-754 floating-point mantissa processing.</p>
      <p><b>Algorithm:</b> The module splits each 24-bit operand into two 12-bit halves (`a_hi`, `a_lo`, `b_hi`, `b_lo`) and applies the Urdhva-Tiryakbhyam sutra, computing four 24-bit partial products via four `vedic12x12` instantiations:</p>
      <ul>
        <li>`p0 = a_lo × b_lo` (aligned at bit position 0)</li>
        <li>`p1 = a_lo × b_hi` (shifted left by 12 bits)</li>
        <li>`p2 = a_hi × b_lo` (shifted left by 12 bits)</li>
        <li>`p3 = a_hi × b_hi` (shifted left by 24 bits)</li>
      </ul>
      <p>The final 48-bit product is computed combinationally as: `p = term0 + term1 + term2 + term3`, where each term represents the appropriately shifted partial product. The synthesis tool automatically optimizes this multi-operand addition into an efficient carry-save or parallel-prefix adder tree, minimizing critical path delay.</p>
      <p><b>Resource Utilization:</b> The module instantiates four `vedic12x12` units and a 48-bit adder network. Due to the hierarchical decomposition, the adder fanout is well-balanced, facilitating high-frequency operation on FPGA fabrics.</p>

      <h4>7.3 12-bit Vedic Multiplier: `vedic12x12.v`</h4>
      <p>The `vedic12x12` module extends the Vedic methodology to 12-bit operands, producing a 24-bit product. It mirrors the structure of `vedic24x24`, partitioning inputs into 6-bit segments and recursively applying the Urdhva-Tiryakbhyam algorithm.</p>
      <p><b>Implementation:</b> Four `vedic6x6` instances compute partial products (`p0`, `p1`, `p2`, `p3`), which are then shifted and summed: `p = p0 + (p1<<6) + (p2<<6) + (p3<<12)`. The combinational adder network efficiently combines these terms into the final 24-bit product.</p>
      <p><b>Design Considerations:</b> The 6-bit shift intervals maintain arithmetic alignment and minimize carry propagation complexity. This intermediate hierarchy level balances logic depth and fanout, achieving optimal synthesis results across diverse FPGA families.</p>

      <h4>7.4 6-bit Vedic Multiplier: `vedic6x6.v`</h4>
      <p>The `vedic6x6` module processes 6-bit inputs to generate a 12-bit product, serving as the penultimate layer in the Vedic hierarchy. Inputs are split into 3-bit segments, with four `vedic3x3` instantiations computing partial products.</p>
      <p><b>Datapath:</b> Partial products are aligned and summed: `p = term0 + term1 + term2 + term3`, where `term1` and `term2` are left-shifted by 3 bits, and `term3` is left-shifted by 6 bits. The combinational logic ensures that all partial sums converge within a single clock cycle (when used in a pipelined context), contributing to the overall low-latency characteristic of the design.</p>
      <p><b>Synthesis Optimization:</b> Modern synthesis tools recognize this pattern and map it to optimized LUT-based adder structures, reducing both area and delay.</p>

      <h4>7.5 3-bit Vedic Base Multiplier: `vedic3x3.v`</h4>
      <p>The `vedic3x3` module forms the fundamental building block of the entire Vedic multiplier tree. It computes the product of two 3-bit unsigned integers, producing a 6-bit result using purely combinational logic.</p>
      <p><b>Implementation Strategy:</b> Due to the small operand size, the module employs direct bitwise AND operations to generate partial product terms, followed by manual carry-propagate addition or, for simplicity and correctness, leverages the synthesizer's ability to optimize the expression `p = a * b` into an efficient gate-level netlist. This approach guarantees functional correctness while allowing synthesis tools to apply vendor-specific optimizations (e.g., dedicated multiplier primitives or LUT-based implementations).</p>
      <p><b>Critical Role:</b> As the leaf node of the multiplication tree, `vedic3x3` is instantiated 256 times in the complete `vedic24x24` hierarchy (64 instances in each `vedic6x6`, 16 `vedic6x6` in each `vedic12x12`, etc.). Its simplicity and low gate count ensure minimal area overhead and maximum reusability.</p>

      <h4>7.6 Testbench: `tb_fp_mul_pipelined.v`</h4>
      <p>A comprehensive self-checking testbench, `tb_fp_mul_pipelined`, was developed to validate functional correctness across the IEEE-754 specification. The testbench instantiates the `fp_mul_pipelined` DUT (Device Under Test) and applies a suite of test vectors covering normal arithmetic, special cases (zero, infinity, NaN), and boundary conditions (overflow, underflow).</p>
      <p><b>Clock Generation:</b> A 100 MHz clock (10 ns period) is generated via an `always` block, simulating a realistic FPGA operating frequency.</p>
      <p><b>Test Methodology:</b> The `apply_input` task encapsulates the test vector application procedure. It drives the `a`, `b`, and `valid_in` inputs, then polls the `valid_out` signal with a timeout mechanism (40 clock cycles) to detect pipeline completion. Upon receiving `valid_out`, the task invokes `check_and_report` to compare the actual output (`y`) against the expected result (`expY`), logging PASS/FAIL status with detailed diagnostic information (hex values, timestamps).</p>
      <p><b>Test Coverage:</b></p>
      <ul>
        <li><b>Case 1 (Normal Operation):</b> `3.5 × -2.0 = -7.0` validates correct sign handling, exponent arithmetic, and mantissa multiplication.</li>
        <li><b>Case 2 (Fractional Operands):</b> `1.5 × 2.0 = 3.0` tests normalized mantissa processing.</li>
        <li><b>Case 3 (Zero Handling):</b> `0.0 × 5.0 = 0.0` confirms zero detection and propagation.</li>
        <li><b>Case 4 (Infinity Arithmetic):</b> `+Inf × 2.0 = +Inf` verifies infinity preservation.</li>
        <li><b>Case 5 (NaN Propagation):</b> `NaN × 2.0 = NaN` ensures highest-priority exception handling, with the canonical quiet NaN (`0x7FC00000`) generated by the design.</li>
      </ul>
      <p><b>VCD Waveform Dumping:</b> The testbench generates a Value Change Dump (VCD) file (`waveforms_all.vcd`) via `$dumpfile` and `$dumpvars`, enabling detailed waveform analysis in tools such as GTKWave or Vivado's built-in waveform viewer. This facilitates debugging and timing verification.</p>
      <p><b>Timeout Handling:</b> If `valid_out` does not assert within the expected window, the testbench logs a timeout error, aiding in the detection of pipeline stalls or incorrect control logic.</p>
      <p><b>Extensibility:</b> The modular task-based structure allows straightforward addition of new test cases, making the testbench suitable for regression testing and continuous integration workflows.</p>

      <h4>7.7 Design Verification and Coding Standards</h4>
      <p>All Verilog modules strictly adhere to synthesizable RTL coding practices. No unsynthesizable constructs (e.g., delays in non-testbench code, `initial` blocks in synthesizable modules) are present. The design uses blocking assignments (`=`) only in combinational `always @*` blocks and non-blocking assignments (`<=`) in sequential `always @(posedge clk)` blocks, eliminating race conditions and ensuring deterministic simulation and synthesis behavior.</p>
      <p>Parameterization and modularity enable straightforward adaptation to different precision requirements (e.g., extending to IEEE-754 double precision) or alternative multiplication algorithms. Each module is self-contained with clearly defined interfaces, promoting design reuse and IP integration.</p>


      <div class="schematic-section">
        <h3>8. Schematic Overview</h3>
        <p class="schematic-intro">After the Verilog HDL code was synthesized using the Vivado Design Suite, a Register-Transfer Level (RTL)
          schematic was generated. This schematic provides a visual representation of the hardware architecture.</p>

        <figure class="diagram schematic-figure" id="diagram-rtl-schematic">
          <img src="assets/rtl_schematic.png" alt="Register Transfer Level schematic from Vivado synthesis"
            onerror="this.parentElement.innerHTML='<div class=\'placeholder\'>[Figure 5: RTL Schematic - Image: assets/rtl_schematic.png]</div>'">
          <figcaption><strong>Fig. 5:</strong> RTL Schematic</figcaption>
        </figure>

        <p>The RTL schematic provides a comprehensive view of the synthesized hardware implementation, clearly illustrating the two-stage pipelined architecture that forms the core of the floating-point multiplier design. The spatial organization from left to right directly corresponds to the temporal progression through the pipeline stages, making the data flow and computational partitioning immediately apparent.</p>
        
        <p><b>Stage 1 Architecture (Left Half):</b> The first stage occupies the left portion of the schematic and contains the most computationally intensive operations. At the input boundary, we observe the `a[31:0]` and `b[31:0]` input ports feeding into a bank of 32-bit registers, which capture the incoming operands on the rising edge of `clk` when `valid_in` is asserted. These input registers ensure that the operands remain stable throughout the entire computation cycle, preventing any timing issues due to changing inputs. Immediately following the input registers, the schematic reveals the field extraction logic, which decomposes each 32-bit floating-point number into its constituent sign bit (S), 8-bit exponent (E), and 23-bit fraction (F) fields. This extraction is purely combinational, implemented via simple bit-slicing operations that route specific wire ranges to different computational units.</p>
        
        <p>The dominant feature of Stage 1 is the large hierarchical block labeled `vedic24x24`, which performs the unsigned integer multiplication of the extended 24-bit mantissas (the hidden '1' bit concatenated with the 23-bit fraction). The schematic clearly exposes the recursive Vedic multiplier hierarchy: the top-level `vedic24x24` instance is constructed from four `vedic12x12` sub-modules (visible as nested blocks within the larger structure), each of which is in turn built from four `vedic6x6` modules, and finally, each `vedic6x6` comprises four `vedic3x3` base multipliers. This nested, tree-like structure is visually evident in the schematic, with interconnecting carry and sum buses forming a structured lattice pattern. The synthesis tool has preserved this hierarchy to facilitate design understanding and timing analysis, although in the final netlist, all levels are flattened into a single optimized logic cloud.</p>
        
        <p>Adjacent to the Vedic multiplier block, the exponent addition logic is visible as a compact adder structure that computes `E_a + E_b - 127`, producing the raw exponent for the product. The sign calculation logic, a simple XOR gate (`sign_result = sign_a ^ sign_b`), is also present but occupies minimal area due to its trivial Boolean complexity. All these Stage 1 computations are purely combinational; no internal registers exist within this stage except at the boundaries.</p>
        
        <p><b>Pipeline Register Bank (Center):</b> A prominent vertical column of flip-flops is clearly visible in the center of the schematic, forming a distinct boundary between the two stages. This register bank captures all intermediate results from Stage 1—the 48-bit raw mantissa product, the raw exponent sum, the result sign bit, and the special case flags (zero, infinity, NaN detection signals)—on the rising edge of `clk`. The presence of these registers is the defining characteristic of the pipelined architecture: they cut the critical path in half, allowing each stage to operate at a much higher clock frequency than would be possible in a single-cycle combinational design. The schematic shows these registers as a clean, organized array, emphasizing their role as a synchronization barrier.</p>
        
        <p><b>Stage 2 Architecture (Right Half):</b> The second stage, occupying the right portion of the schematic, is dominated by a large multiplexer network that implements the IEEE-754 special case priority logic. This logic examines the special case flags propagated from Stage 1 and determines which result to output: if either operand is NaN, the output is forced to the canonical quiet NaN (`32'h7FC00000`); if both operands are infinity, the result is infinity with the correct sign; if either operand is zero, the output is zero; otherwise, the normalized product from the mantissa and exponent computation is selected. The schematic reveals this priority logic as a tree of 2:1 multiplexers, with the NaN case having the highest priority (implemented as the final multiplexer stage closest to the output).</p>
        
        <p>In the normalized result path, the normalization and rounding logic is visible. The 48-bit raw product from Stage 1 is examined to determine whether the leading bit is set (indicating a product in the range [2, 4), requiring a right shift and exponent increment) or clear (product in range [1, 2), already normalized). The schematic shows the barrel shifter or conditional shift logic that performs this adjustment, followed by the rounding unit that truncates the 48-bit mantissa to 23 bits according to the IEEE-754 round-to-nearest-even rule (though for simplicity, our design uses truncation, which corresponds to round-toward-zero). The final 32-bit result is assembled by concatenating the sign bit, the adjusted 8-bit exponent, and the rounded 23-bit fraction.</p>
        
        <p>At the output boundary, another bank of registers captures the final result `y[31:0]` and the `valid_out` signal, ensuring clean, glitch-free outputs that are synchronized to the clock edge. The `valid_out` signal is generated by a simple 2-bit shift register (visible as a small chain of flip-flops) that delays the `valid_in` signal by exactly two clock cycles, matching the pipeline depth.</p>
        
        <p><b>Control and Handshaking Logic:</b> Throughout the schematic, the clock (`clk`) and active-low reset (`rstn`) signals are distributed to all registers, forming a global timing reference. The reset logic ensures that all flip-flops initialize to a known state (typically zero) upon power-up or explicit reset, preventing undefined behavior. The handshaking signals `valid_in` and `valid_out` are routed alongside the data paths, providing a simple but robust flow control mechanism that allows upstream and downstream modules to coordinate data transfers without requiring complex state machines.</p>
        
        <p>The hierarchical organization, the clear separation of pipeline stages, and the efficient utilization of FPGA resources (LUTs for combinational logic, flip-flops for registers, and potentially DSP slices for portions of the Vedic multiplier) are all evident in the RTL schematic, providing strong confirmation that the Verilog HDL code has been correctly interpreted and optimized by the synthesis tool.</p>
      </div>

      <h3>9. Simulation and Waveform Analysis</h3>
      <p>The design was functionally verified by simulating the `tb_fp_mul_pipelined` testbench in the Vivado simulator.
        The testbench was designed to cover normal operation as well as all special cases defined by the IEEE-754
        standard, including zero multiplication, NaN propagation, infinity handling, and edge cases involving denormalized numbers. Each test case applies specific input operands and monitors the output to ensure bit-exact correctness, verifying both the computational accuracy and the proper timing of the pipeline's handshaking signals (`valid_in` and `valid_out`).</p>
      <p>The testbench generates a 100 MHz clock (10 ns period). The `apply_input` task asserts `valid_in` for one
        cycle. Due to the two-stage pipeline, the corresponding `valid_out` signal is expected to go high <i>two</i>
        clock cycles later.</p>

      <h4>Case 1: Normal Operation (3.5 × -2.0)</h4>
      <ul>
        <li><b>Input A:</b> `3.5` = `32'h40600000`</li>
        <li><b>Input B:</b> `-2.0` = `32'hC0000000`</li>
        <li><b>Expected Y:</b> `-7.0` = `32'hC0E00000`</li>
      </ul>
      <figure class="diagram" id="diagram-waveform-normal">
        <img src="assets/waveform_normal.png" alt="Simulation waveform for normal multiplication (3.5 × -2.0)"
          onerror="this.parentElement.innerHTML='<div class=\'placeholder\'>[Figure 6: Simulation Waveform - Normal Operation - Image: assets/waveform_normal.png]</div>'">
        <figcaption><strong>Fig. 6:</strong> Simulation Waveform - Normal Operation</figcaption>
      </figure>
      <p>The waveform shows the inputs `a` and `b` being applied. Two clock cycles later, the output `y` correctly
        settles to `C0E00000` and `valid_out` pulses high for one cycle, confirming the correct result and pipeline
        latency.</p>

      <h4>Case 2: Zero Handling (0 × 5.0)</h4>
      <ul>
        <li><b>Input A:</b> `0.0` = `32'h00000000`</li>
        <li><b>Input B:</b> `5.0` = `32'h40A00000`</li>
        <li><b>Expected Y:</b> `0.0` = `32'h00000000`</li>
      </ul>
      <figure class="diagram" id="diagram-waveform-zero">
        <img src="assets/waveform_zero.png" alt="Simulation waveform for zero multiplication (0 × 5.0)"
          onerror="this.parentElement.innerHTML='<div class=\'placeholder\'>[Figure 7: Simulation Waveform - Zero Handling - Image: assets/waveform_zero.png]</div>'">
        <figcaption><strong>Fig. 7:</strong> Simulation Waveform - Zero Handling</figcaption>
      </figure>
      <p>As seen in the simulation waveform, the special case logic in Stage 1 detects the zero input early in the pipeline by examining the exponent and fraction fields. In Stage 2, the priority
        selector multiplexer evaluates the zero flag and bypasses the normalization logic, directly routing the correct zero representation (`32'h00000000`) to the output register, ensuring strict IEEE-754 compliance and preventing any unnecessary computation.</p>

      <h4>Case 3: NaN Handling (NaN × 2.0)</h4>
      <ul>
        <li><b>Input A:</b> `NaN` = `32'h7FC00001` (E=all 1s, F!=0)</li>
        <li><b>Input B:</b> `2.0` = `32'h40000000`</li>
        <li><b>Expected Y:</b> `NaN` = `32'h7FC00000` (Quiet NaN)</li>
      </ul>
      <figure class="diagram" id="diagram-waveform-nan">
        <img src="assets/waveform_nan.png" alt="Simulation waveform for NaN multiplication"
          onerror="this.parentElement.innerHTML='<div class=\'placeholder\'>[Figure 8: Simulation Waveform - NaN Handling - Image: assets/waveform_nan.png]</div>'">
        <figcaption><strong>Fig. 8:</strong> Simulation Waveform - NaN Handling</figcaption>
      </figure>
      <p>The waveform confirms that as soon as the NaN input is detected, the NaN logic takes highest priority. The
        output `y` is forced to `7FC00000`, which is the canonical quiet NaN representation hardcoded in our design,
        propagating the NaN state as required by the standard. Infinity Handling (Inf × 2.0) and the (Inf × 0) cases
        were also tested and produced the correct `+Inf` and `NaN` outputs, respectively.</p>

      <h3>10. Results</h3>
      <p>The project successfully yielded a functionally correct 32-bit floating-point multiplier. The results are
        summarized in two categories:</p>
      <p><b>1. Functional Verification:</b><br>
        The simulation results confirm that the designed multiplier is 100% logically correct for all tested cases.
      <ul>
        <li><b>Normal Multiplication:</b> Products are accurate.</li>
        <li><b>Pipeline:</b> A 2-cycle latency and 1-cycle throughput are confirmed.</li>
        <li><b>Special Cases:</b> Zero, Infinity, and NaN inputs are handled correctly according to IEEE-754 rules.</li>
        <li><b>Exception Handling:</b> Overflow cases correctly result in Infinity. Underflow cases correctly result in
          Zero. The `Inf × 0` case correctly produces NaN.</li>
      </ul>
      </p>
      <p><b>2. Synthesis and Performance (Analysis):</b><br>
        While a full physical implementation was not the primary goal, a synthesis of the design in Vivado provides key
        insights:
      <ul>
        <li><b>Area/Resource Utilization:</b> The Vedic multiplier's regular, hierarchical structure is highly amenable
          to FPGA logic fabric. The design synthesizes to a combination of Look-Up Tables (LUTs) and Flip-Flops (for
          pipeline registers).</li>
        <li><b>Timing/Performance:</b> The 2-stage pipeline successfully breaks the critical path. The maximum operating
          frequency (Fmax) is determined by the delay of Stage 1, which is significantly faster than a non-pipelined
          version.</li>
        <li><b>Throughput:</b> The design achieves a peak throughput of one multiplication per clock cycle, making it
          ideal for applications requiring a continuous stream of calculations, such as in FIR filters or matrix
          multiplication engines.</li>
      </ul>
      </p>

      <h3>11. Conclusion</h3>
      <p>This project has successfully demonstrated the design, implementation, and verification of a high-speed,
        two-stage pipelined IEEE-754 single-precision floating-point multiplier.</p>
      <p>The key achievement of this work is the novel and effective use of a <b>hierarchical 24×24 Vedic multiplier</b>
        based on the Urdhva-Tiryagbhyam sutra for the mantissa calculation. This approach was shown to be highly
        effective, creating a parallel and regular hardware structure that is efficient for VLSI implementation.</p>
      <p>The two-stage pipelined architecture successfully increases the throughput of the multiplier, making it capable
        of handling high-speed data streams. The Verilog HDL implementation was comprehensively simulated and verified
        in the Vivado Design Suite, proving its functional correctness. The design robustly handles all special cases,
        including Zero, Infinity, and NaN, as well as overflow and underflow conditions, ensuring full compliance with
        the IEEE-754 standard.</p>
      <p>This project validates that the fusion of ancient mathematical algorithms with modern digital design principles
        (like pipelining) can yield high-performance, efficient, and scalable arithmetic circuits suitable for modern
        FPGAs.</p>

      <h3>12. Future Scope</h3>
      <p>This project lays a strong foundation for several future enhancements:</p>
      <ol>
        <li><b>Double Precision:</b> The architecture can be extended to support the 64-bit double-precision format.
          This would primarily involve scaling the Vedic multiplier to a 53×53 hierarchy and expanding the exponent path
          to 11 bits.</li>
        <li><b>Advanced Rounding:</b> The current design uses truncation (round-to-zero). This could be replaced with
          more complex rounding modes specified by the standard, such as "round-to-nearest-even."</li>
        <li><b>Denormalized Numbers:</b> The multiplier could be enhanced to provide full support for denormalized
          (subnormal) input operands and results, which are currently flushed to zero.</li>
        <li><b>Deeper Pipelining:</b> To achieve even higher clock frequencies, the design could be partitioned into a
          deeper pipeline (e.g., 3 or 4 stages) by placing registers within the adder tree of the `vedic24x24` module.
        </li>
        <li><b>ASIC Implementation:</b> The Verilog design can be synthesized for an ASIC (Application-Specific
          Integrated Circuit) process to perform a detailed analysis of its power consumption, area, and timing.</li>
      </ol>

      <h3>13. Acknowledgment</h3>
      <p>We would like to express our sincere gratitude to our project supervisor, <b>Prof. P. Venkateswaran</b>, for
        his invaluable guidance, continuous support, and insightful feedback throughout this project. His expertise in
        digital design and VLSI systems proved instrumental in shaping the direction of this research and refining our
        approach to the hierarchical multiplier architecture. His encouragement to explore unconventional methods, such
        as the application of Vedic mathematics to modern hardware design, broadened our perspective and strengthened
        the innovation in this work.</p>
      <p>We extend our appreciation to the <b>Department of Electronics and Telecommunication Engineering</b> at
        <b>Jadavpur University</b> for providing access to state-of-the-art laboratory facilities, software tools
        including Xilinx Vivado Design Suite, and a conducive academic environment that enabled us to complete this
        work. The department's emphasis on research-driven learning and hands-on experimentation was crucial to the
        successful completion of this project.
      </p>
      <p>We are also grateful to our peers and fellow researchers in the department for their constructive discussions,
        suggestions, and collaborative spirit during the course of this project. Special thanks to the faculty members
        who provided valuable insights during our interim presentations and helped us identify potential improvements in
        our design methodology.</p>
      <p>Finally, we acknowledge the contributions of the global research community whose published works in the field of
        floating-point arithmetic, Vedic mathematics, and VLSI design served as the foundation for this study. The
        open-access nature of academic literature and the spirit of knowledge sharing enabled us to build upon existing
        research and contribute our findings to this evolving field.</p>

      <h3>14. Author Contributions</h3>
      <p>This research represents a collaborative effort with distinct contributions from each author, while maintaining
        shared responsibility for the overall project outcomes.</p>
      <p><b>Krishnarjun Mitra</b> served as the principal architect and implementer of the floating-point multiplier
        system. His responsibilities included:</p>
      <ul>
        <li>Complete design and implementation of the two-stage pipelined floating-point multiplier architecture in
          Verilog HDL</li>
        <li>Development of the hierarchical Vedic multiplier modules (3×3, 6×6, 12×12, and 24×24) based on the
          Urdhva-Tiryagbhyam sutra</li>
        <li>Design and coding of all special case handling logic for Zero, Infinity, NaN, overflow, and underflow
          conditions</li>
        <li>Creation of the comprehensive testbench environment and execution of functional verification simulations in
          Vivado</li>
        <li>Synthesis and timing analysis of the design, including RTL schematic generation and resource utilization
          assessment</li>
        <li>Preparation of all technical documentation, including this manuscript, diagrams, waveform analysis, and code
          commentary</li>
        <li>Development of the project website, integration of interactive elements, and establishment of online
          accessibility</li>
      </ul>
      <p><b>Souvik Das</b> contributed significantly to the theoretical foundation and validation of the project through:
      </p>
      <ul>
        <li>Comprehensive literature review and comparative analysis of existing floating-point multiplier architectures
        </li>
        <li>Theoretical study of Vedic mathematics principles and their applicability to digital circuit design</li>
        <li>Conceptual discussions on architectural choices, pipeline depth optimization, and design trade-offs</li>
        <li>Critical review and validation of simulation results against IEEE-754 standard specifications</li>
        <li>Manuscript proofreading, formatting, and technical accuracy verification</li>
        <li>Assistance in preparation of presentations and documentation of comparative performance metrics</li>
      </ul>
      <p>Both authors participated equally in project planning, weekly progress reviews, problem-solving discussions, and
        the formulation of conclusions and future scope. All design decisions were made collaboratively, ensuring that
        the final implementation reflects a unified vision and balanced approach to the research objectives.</p>

      <h3>15. References</h3>
      <p>[1] M. S. H. Hemant and N. Raghuwanshi, "VLSI design and analysis of IEEE 754 Floating Point Multiplier,"
        <i>International Journal of Science, Engineering and Technology (IJSET)</i>, vol. 10, no. 2, 2022.
      </p>
      <p>[2] H. Ghabeli, "Design of Floating-Point Multiplier Architecture with Adaptive Data Timing Channels," <i>2024
          6th Iranian International Conference on Microelectronics (IICM)</i>, 2024.</p>
      <p>[3] N. Bai, H. Li, J. Lv, S. Yang, and Y. Xu, "Logic Design and Power Optimization of Floating-Point
        Multipliers," <i>Computational Intelligence and Neuroscience</i>, vol. 2022, Article ID 6949846, 2022.</p>
      <p>[4] S. Havaldar and K. S. Gurumurthy, "Design Of Vedic IEEE 754 Floating Point Multiplier," <i>2016 IEEE
          International Conference On Recent Trends In Electronics Information Communication Technology (RTEICT)</i>,
        May 20-21, 2016, India.</p>
      <p>[5] IEEE, <i>IEEE Standard for Floating-Point Arithmetic</i>, IEEE 754-2019, 2019.</p>

    </div>
  </div>

  <footer class="site-footer">
    <div class="footer-content">
      <p class="footer-author">Created and maintained by <strong>Krishnarjun Mitra</strong></p>
      <p class="footer-affiliation">Department of Electronics and Telecommunication Engineering, Jadavpur University</p>
      <p class="footer-copyright">&copy; 2025 Krishnarjun Mitra. All rights reserved.</p>
    </div>
  </footer>

  <div class="read-progress" role="progressbar" aria-label="Reading progress">
    <div class="read-progress__bar" id="readProgressBar"></div>
  </div>
  <div class="read-progress__label" id="readProgressLabel">0% • 100% left</div>
  <div class="fab-container" aria-label="Quick actions">
    <!-- <button class="fab" onclick="downloadPDF()" title="Download PDF" aria-label="Download PDF">
      <svg width="28" height="28" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
        <path d="M12 3v12m0 0l-5-5m5 5l5-5" />
        <path d="M5 19h14" />
      </svg>

    </button> -->
    <button class="fab" onclick="triggerPrint()" title="Print" aria-label="Print">
      <svg viewBox="0 0 24 24" role="img" aria-hidden="true">
        <path
          d="M6 9V2h12v7h2c1.1 0 2 .9 2 2v6h-4v3H6v-3H2v-6c0-1.1.9-2 2-2h2zm2-5v5h8V4H8zm8 14H8v1h8v-1zm4-4v-4H4v4h16z" />
      </svg>
    </button>
  </div>
</body>

</html>
