<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <meta name="google-site-verification" content="mtFBoyc2JBmbAuiZSxWCWLl4LFWQ9aON4H31IEK4THI" />

  <!-- Primary Meta Tags -->
  <title>IEEE-754 Floating Point Multiplier | Vedic Mathematics VLSI Design | Krishnarjun Mitra | Jadavpur University
  </title>
  <meta name="title"
    content="IEEE-754 Floating Point Multiplier using Vedic Mathematics - Research by Krishnarjun Mitra">
  <meta name="description"
    content="High-Speed Pipelined IEEE-754 Single-Precision Floating Point Multiplier using Hierarchical Vedic 24×24 Mantissa Architecture. VLSI design research project by Krishnarjun Mitra and Souvik Das at Jadavpur University. Verilog HDL implementation, FPGA optimization, Urdhva-Tiryagbhyam sutra.">
  <meta name="keywords"
    content="IEEE-754, floating point multiplier, Vedic mathematics, Urdhva-Tiryagbhyam, VLSI design, Verilog HDL, FPGA, high-speed multiplier, pipelined architecture, mantissa multiplication, Krishnarjun Mitra, Souvik Das, Jadavpur University, digital design, computer arithmetic, Vedic multiplier, hierarchical multiplier, hardware acceleration, ASIC design, digital signal processing, DSP, binary multiplication, Booth multiplier, Wallace tree, hardware optimization, synthesizable Verilog, RTL design, Vivado, Xilinx, electronics engineering, telecommunication engineering, research paper, academic research, final year project, undergraduate research, Indian university research, Kolkata research, Bengal engineering, semiconductor design, chip design, processor design, arithmetic circuits, combinational logic, sequential logic, pipeline design, throughput optimization, FPGA implementation, hardware description language, digital electronics, embedded systems, microelectronics, nanoelectronics, IC design, integrated circuits, computer architecture, reconfigurable computing, parallel processing">
  <meta name="author" content="Krishnarjun Mitra, Souvik Das">
  <meta name="robots" content="index, follow">
  <link rel="canonical" href="https://finalyearproject.vercel.app">

  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="website">
  <meta property="og:url" content="https://finalyearproject.vercel.app">
  <meta property="og:title" content="IEEE-754 Floating Point Multiplier using Vedic Mathematics | VLSI Research">
  <meta property="og:description"
    content="High-performance pipelined floating point multiplier design using ancient Vedic mathematics. Research by Krishnarjun Mitra at Jadavpur University. Complete Verilog HDL implementation with FPGA optimization.">
  <meta property="og:image" content="https://finalyearproject.vercel.app/assets/Jadavpur_University.png">
  <meta property="og:site_name" content="Krishnarjun Mitra - VLSI Research">

  <!-- Twitter -->
  <meta property="twitter:card" content="summary_large_image">
  <meta property="twitter:url" content="https://finalyearproject.vercel.app">
  <meta property="twitter:title" content="IEEE-754 Floating Point Multiplier using Vedic Mathematics">
  <meta property="twitter:description"
    content="High-speed pipelined floating point multiplier research using Vedic mathematics and Verilog HDL. Jadavpur University final year project.">
  <meta property="twitter:image" content="https://finalyearproject.vercel.app/assets/Jadavpur_University.png">

  <!-- Additional SEO Tags -->
  <meta name="classification" content="Research, Academic, VLSI, Electronics Engineering">
  <meta name="coverage" content="Worldwide">
  <meta name="distribution" content="Global">
  <meta name="rating" content="General">
  <meta name="revisit-after" content="7 days">
  <meta name="language" content="English">
  <meta name="geo.region" content="IN-WB">
  <meta name="geo.placename" content="Kolkata, West Bengal, India">
  <meta name="geo.position" content="22.5726;88.3639">
  <meta name="ICBM" content="22.5726, 88.3639">

  <!-- Academic Meta Tags -->
  <meta name="citation_title"
    content="Design and Implementation of a High-Speed Pipelined IEEE-754 Floating Point Multiplier using Hierarchical Vedic 24×24 Mantissa Architecture">
  <meta name="citation_author" content="Mitra, Krishnarjun">
  <meta name="citation_author" content="Das, Souvik">
  <meta name="citation_publication_date" content="2025">
  <meta name="citation_institution" content="Jadavpur University">
  <meta name="citation_department" content="Department of Electronics and Telecommunication Engineering">
  <meta name="citation_keywords"
    content="IEEE-754, Floating Point Multiplier, Pipelining, Vedic Mathematics, Urdhva-Tiryagbhyam, Verilog, FPGA, High-Speed Arithmetic, VLSI">

  <!-- Structured Data (JSON-LD) -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "ScholarlyArticle",
    "headline": "Design and Implementation of a High-Speed Pipelined IEEE-754 Floating Point Multiplier using Hierarchical Vedic 24×24 Mantissa Architecture",
    "author": [
      {
        "@type": "Person",
        "name": "Krishnarjun Mitra",
        "affiliation": {
          "@type": "Organization",
          "name": "Jadavpur University",
          "department": "Department of Electronics and Telecommunication Engineering",
          "address": {
            "@type": "PostalAddress",
            "addressLocality": "Kolkata",
            "addressRegion": "West Bengal",
            "addressCountry": "India"
          }
        }
      },
      {
        "@type": "Person",
        "name": "Souvik Das",
        "affiliation": {
          "@type": "Organization",
          "name": "Jadavpur University"
        }
      }
    ],
    "datePublished": "2025",
    "publisher": {
      "@type": "Organization",
      "name": "Jadavpur University"
    },
    "keywords": "IEEE-754, Floating Point Multiplier, Pipelining, Vedic Mathematics, Urdhva-Tiryagbhyam, Verilog, FPGA, High-Speed Arithmetic, VLSI, Digital Design, Hardware Architecture",
    "abstract": "High-performance floating-point arithmetic is a foundational requirement for modern computing. This research presents the design, implementation, and verification of a high-speed, two-stage pipelined floating-point multiplier compliant with the IEEE-754 single-precision standard using hierarchical Vedic multiplier based on the Urdhva-Tiryagbhyam sutra.",
    "inLanguage": "en",
    "about": [
      "VLSI Design",
      "Digital Electronics",
      "Computer Architecture",
      "Floating Point Arithmetic",
      "Vedic Mathematics",
      "FPGA Design"
    ]
  }
  </script>

  <link rel="icon" type="image/png" href="favicon-small.png">
  <link rel="shortcut icon" type="image/png" href="favicon-small.png">
  <link rel="apple-touch-icon" sizes="180x180" href="favicon.png">
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link
    href="https://fonts.googleapis.com/css2?family=Merriweather:wght@300;400;700;900&family=Source+Sans+3:wght@300;400;600;700&display=swap"
    rel="stylesheet">
  <link rel="stylesheet" href="style.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/html2pdf.js/0.10.1/html2pdf.bundle.min.js"
    integrity="sha512-GsEyh8GgYfUdw2GFqtZUt8gmfSdJQOnE5n9PpG1GQJzCqJrjVfGqYwIV/pY5Pja/qvp5AYA9YVBus7PAGfQ1HA=="
    crossorigin="anonymous" referrerpolicy="no-referrer"></script>
  <script src="assets/assets.js"></script>
  <script src="app.js" defer></script>
</head>

<body>

  <button id="toc-toggle" class="toc-toggle" aria-controls="toc-drawer" aria-expanded="false"
    aria-label="Toggle table of contents">Contents</button>
  <aside id="toc-drawer" class="toc-drawer" aria-label="Table of Contents Drawer" aria-hidden="true">
    <button id="toc-close" class="toc-close" aria-label="Hide contents" title="Hide">
      <svg viewBox="0 0 24 24" aria-hidden="true">
        <path d="M15.41 7.41 14 6l-6 6 6 6 1.41-1.41L10.83 12z" />
      </svg>
    </button>
    <nav class="toc" aria-label="Table of Contents">
      <h2>Contents</h2>
      <ol id="toc-list"></ol>
    </nav>
  </aside>

  <div class="container" id="report">

    <div class="title-page">
      <div>
        <h1>Design and Implementation of a High-Speed Pipelined IEEE-754 Floating Point Multiplier using Hierarchical
          Vedic 24×24 Mantissa Architecture</h1>
        <br>
        <h2>A Final Year Project Report</h2>
        <p>Submitted in partial fulfillment of the requirements for the degree of</p>
        <h3>Bachelor of Engineering</h3>
        <p>in</p>
        <h3>Electronics and Telecommunication Engineering</h3>
        <br>
        <div class="authors">
          by<br>
          <b>Krishnarjun Mitra</b><br>
          <b>Souvik Das</b><br>
          (Session 2022–2026)
        </div>
        <br>
        <div class="supervisor">
          Under the supervision of<br>
          <b>Prof. P. Venkateshwaran</b>
        </div>
      </div>
      <div class="university-info">
        <div class="logo-placeholder">
          <img src="assets/Jadavpur_University.png" alt="Jadavpur University Logo" />
        </div>
        <h3>Department of Electronics and Telecommunication Engineering</h3>
        <h3>JADAVPUR UNIVERSITY</h3>
        <p>Kolkata, India</p>
        <p>2025</p>
      </div>
    </div>

    <section class="preface">
      <h2>Preface</h2>
      <p>This report documents the conception, design, verification, and analysis of a high-speed pipelined
        IEEE&#x2011;754 single-precision floating point multiplier employing a hierarchical Vedic 24&times;24 mantissa
        architecture. The work was undertaken as part of the Final Year Project requirement at Jadavpur University and
        reflects a synthesis of classic computer arithmetic, modern digital design methodologies, and ancient Vedic
        mathematical principles chosen for their structural regularity and hardware efficiency.</p>
      <p>The project objective was twofold: (1) engineer a logically correct and throughput-optimized multiplier
        suitable for FPGA deployment, and (2) evaluate the viability of recursive Urdhva&#x2011;Tiryagbhyam
        decomposition versus conventional Booth / Wallace techniques in terms of modularity and pipeline friendliness.
        Emphasis was placed on clean, synthesizable Verilog HDL, deterministic handling of IEEE special cases, and
        architectural clarity enabling future extension to double precision and deeper pipelines.</p>
      <p>This Preface provides context for readers approaching the subsequent technical sections. The Literature Review
        situates our design amid contemporary optimization strategies; architectural chapters then detail field
        extraction, special case logic, exponent path, and mantissa multiplication hierarchy. Simulation evidence,
        followed by synthesis discussion, establishes functional soundness and practical feasibility.</p>
      <ul class="author-bios">
        <li><strong>Krishnarjun Mitra</strong> — Primary architect and implementer of the pipelined multiplier,
          hierarchical Vedic modules, verification environment, and documentation integration. Interests include
          high‑performance arithmetic circuits, FPGA acceleration, and algorithm–hardware co‑design.</li>
        <li><strong>Souvik Das</strong> — Contributor in literature analysis, comparative methodology discussions, and
          manuscript review. Academic interests span digital signal processing, numerical methods, and efficient
          datapath structures.</li>
      </ul>
    </section>

    <!-- Print-only QR Code Section -->
    <section class="print-qr-section">
      <div class="qr-code">
        <img src="https://api.qrserver.com/v1/create-qr-code/?size=200x200&data=https://juetce-finalyearproject.vercel.app"
          alt="QR Code to Project Website">
      </div>
      <div class="qr-details">
        <h3>Online Availability</h3>
        <p>The complete project documentation, is available at the following web address:</p>
        <p class="site-url">https://juetce-finalyearproject.vercel.app</p>
        <p class="qr-footer">Scan the QR code or visit the URL to access the digital version of this research work.</p>
      </div>
    </section>

    <div class="preface-separator"></div>

    <!-- Print-only Table of Contents -->
    <section class="print-toc">
      <h2>Table of Contents</h2>
      <ol>
        <li>
          <div class="toc-entry"><span class="toc-title">1. Introduction</span><span class="toc-dots"></span><span
              class="toc-page">5</span></div>
        </li>
        <li>
          <div class="toc-entry"><span class="toc-title">2. Literature Review</span><span class="toc-dots"></span><span
              class="toc-page">6</span></div>
        </li>
        <li>
          <div class="toc-entry"><span class="toc-title">3. IEEE-754 Floating Point Format</span><span
              class="toc-dots"></span><span class="toc-page">7</span></div>
        </li>
        <li>
          <div class="toc-entry"><span class="toc-title">4. Proposed Architecture</span><span
              class="toc-dots"></span><span class="toc-page">8</span></div>
        </li>
        <li>
          <div class="toc-entry"><span class="toc-title">5. Pipeline Architecture</span><span
              class="toc-dots"></span><span class="toc-page">9</span></div>
        </li>
        <li>
          <div class="toc-entry"><span class="toc-title">6. Vedic Mantissa Multiplier</span><span
              class="toc-dots"></span><span class="toc-page">10</span></div>
        </li>
        <li>
          <div class="toc-entry"><span class="toc-title">7. Implementation in Verilog HDL</span><span
              class="toc-dots"></span><span class="toc-page">11</span></div>
        </li>
        <li>
          <div class="toc-entry"><span class="toc-title">8. Schematic Overview</span><span class="toc-dots"></span><span
              class="toc-page">13</span></div>
        </li>
        <li>
          <div class="toc-entry"><span class="toc-title">9. Simulation and Waveform Analysis</span><span
              class="toc-dots"></span><span class="toc-page">14</span></div>
        </li>
        <li>
          <div class="toc-entry"><span class="toc-title">10. Results</span><span class="toc-dots"></span><span
              class="toc-page">15</span></div>
        </li>
        <li>
          <div class="toc-entry"><span class="toc-title">11. Conclusion</span><span class="toc-dots"></span><span
              class="toc-page">16</span></div>
        </li>
        <li>
          <div class="toc-entry"><span class="toc-title">12. Future Scope</span><span class="toc-dots"></span><span
              class="toc-page">16</span></div>
        </li>
        <li>
          <div class="toc-entry"><span class="toc-title">13. Acknowledgment</span><span class="toc-dots"></span><span
              class="toc-page">17</span></div>
        </li>
        <li>
          <div class="toc-entry"><span class="toc-title">14. Author Contributions</span><span
              class="toc-dots"></span><span class="toc-page">18</span></div>
        </li>
        <li>
          <div class="toc-entry"><span class="toc-title">15. References</span><span class="toc-dots"></span><span
              class="toc-page">19</span></div>
        </li>
      </ol>
    </section>

    <div class="main-content">

      <div class="abstract">
        <h3>Abstract</h3>
        <p>High-performance floating-point arithmetic is a foundational requirement for modern computing, powering
          fields from Digital Signal Processing (DSP) to artificial intelligence and scientific computing. The
          floating-point multiplier, in particular, is a critical component that often dictates overall system
          performance and resource utilization. This project presents the design, implementation, and verification of a
          high-speed, two-stage pipelined floating-point multiplier compliant with the IEEE-754 single-precision
          standard. The core innovation of this design lies in the implementation of the 24-bit mantissa multiplication
          stage using a hierarchical Vedic multiplier based on the Urdhva-Tiryagbhyam sutra. This ancient mathematical
          technique is leveraged for its inherent parallelism and structural regularity, making it highly suitable for
          VLSI and FPGA implementation. The architecture is described in synthesizable Verilog HDL and features a
          recursive 3×3 → 6×6 → 12×12 → 24×24 multiplier hierarchy. The pipelined design enhances throughput, while
          dedicated logic ensures correct handling of special cases, including Zero, Infinity (Inf), and Not-a-Number
          (NaN), as well as overflow and underflow conditions. The design was functionally verified through extensive
          simulation in the Vivado Design Suite, demonstrating its logical correctness and adherence to the IEEE-754
          standard.</p>
      </div>

      <div class="keywords">
        <h3>Keywords</h3>
        <p>IEEE-754, Floating Point Multiplier, Pipelining, Vedic Mathematics, Urdhva-Tiryagbhyam, Verilog, FPGA,
          High-Speed Arithmetic, VLSI.</p>
      </div>

      <h3>1. Introduction</h3>
      <p>In the last few decades, the demand for high-performance computing has grown exponentially. Applications in
        digital signal processing (DSP), graphics rendering, scientific simulation, and the burgeoning field of machine
        learning rely heavily on complex mathematical operations [1]. At the heart of these operations is floating-point
        (FP) arithmetic, which provides a wide dynamic range and high precision for representing real numbers [2].</p>
      <p>Within the suite of FP operations, floating-point multiplication is a fundamental and frequently executed
        instruction. However, it is also one of the most resource-intensive and time-consuming, often forming the
        critical path in a processor's datapath [3]. The complexity of an FP multiplier stems from its three main tasks:
        calculating the sign, adding the exponents, and—most significantly—multiplying the large mantissas.</p>
      <p>Traditional approaches to mantissa multiplication, such as the Booth encoding or array multipliers, have been
        highly optimized. However, they can still suffer from complex routing, large area, and significant propagation
        delays. This has spurred research into alternative multiplication algorithms.</p>
      <p>This project explores one such alternative: the application of ancient Vedic mathematics to modern digital
        design. Specifically, we utilize the <b>Urdhva-Tiryagbhyam</b> (vertically and crosswise) sutra, a technique
        known for its parallel and regular structure [4]. The algorithm breaks down a large multiplication into smaller,
        independent cross-products, which are then summed. This "divide and conquer" methodology is inherently parallel
        and maps efficiently onto the hardware structure of an FPGA.</p>
      <p>To further enhance performance, our design incorporates a <b>two-stage pipeline</b>. While any combinational
        multiplier has a significant propagation delay, pipelining allows us to increase the clock frequency and,
        consequently, the data throughput. By registering the intermediate results, we can process one multiplication
        per clock cycle, albeit with an initial two-cycle latency.</p>
      <p>This report details the design and implementation of a complete 32-bit single-precision floating-point
        multiplier. It combines the speed of a pipelined architecture with the structural efficiency of a
        hierarchically-designed 24×24 Vedic mantissa multiplier. The entire system is implemented in Verilog HDL,
        verified in Vivado, and handles all special cases (Zero, Inf, NaN) as specified by the IEEE-754 standard.</p>
      <p>The following sections will cover the relevant literature, the fundamentals of the IEEE-754 standard, the
        detailed architecture of our proposed multiplier, its implementation, and the simulation results that validate
        its correctness.</p>

      <h3>2. Literature Review</h3>
      <p>The optimization of floating-point multipliers is a well-established field of research. Our work builds upon a
        significant body of existing literature while exploring a specific combination of techniques.</p>
      <p><b>Havaldar and Gurumurthy [4]</b> provide a foundational work by also proposing a design for an IEEE-754
        floating-point multiplier using Vedic mathematics. They highlight the Urdhva-Tiryagbhyam sutra's suitability for
        reducing hardware complexity and path delay compared to conventional array or Booth multipliers. Our project
        extends this concept by implementing a deeply hierarchical 3×3 → 6×6 → 12×12 → 24×24 structure for the mantissa
        and integrating it into a formal two-stage pipeline to maximize throughput, a specific architectural detail that
        builds upon their general concept.</p>
      <p>In contrast, <b>Bai et al. [3]</b> focus on a different optimization route, employing an expanded Booth-Wallace
        algorithm. The Wallace tree is a highly optimized method for summing partial products, and Booth encoding is the
        industry standard for reducing their number. This approach represents the "traditional" high-performance design.
        Our project intentionally diverges from this path to explore the Vedic algorithm as a viable alternative,
        comparing its design simplicity and structural regularity against the optimized but more complex Booth-Wallace
        method.</p>
      <p><b>Ghabeli [2]</b> introduces an advanced technique called Multi-Path Mantissa Processing (MPM). This design
        uses adaptive data timing channels, where the computation path's delay varies based on the input data, such as
        detecting leading zeros in the mantissa. This is an alternative method for accelerating the "average-case"
        performance. Our design, instead, focuses on optimizing the "worst-case" delay and maximizing throughput for all
        inputs via a fixed two-stage pipeline.</p>
      <p>Finally, <b>Hemant and Raghuwanshi [1]</b> analyze the impact of different high-speed <i>adders</i> (e.g.,
        Carry Choose Adder) on the exponent calculation path of an FP multiplier. Their work underscores that every part
        of the FPU is a target for optimization. While their focus is on the 8-bit/11-bit exponent addition, our
        project's primary contribution is the optimization of the 24-bit mantissa multiplication path, which is the
        dominant component in terms of complexity and delay.</p>
      <p>In summary, the literature shows diverse approaches to FPU optimization, from adders [1] to Booth-Wallace trees
        [3] and adaptive paths [2]. Our work contributes to this field by focusing on the synthesis of two powerful
        concepts: a deep pipeline for throughput and the Urdhva-Tiryagbhyam algorithm for an efficient, parallel, and
        regular mantissa multiplier [4].</p>

      <h3>3. IEEE-754 Floating Point Format</h3>
      <p>The IEEE-754 standard defines the representation of floating-point numbers in binary. This project implements
        the 32-bit single-precision format.</p>
      <p>A 32-bit FP number is partitioned into three fields:</p>
      <ul>
        <li><b>Sign (S):</b> 1 bit (Bit 31). `0` for positive, `1` for negative.</li>
        <li><b>Exponent (E):</b> 8 bits (Bits 30-23). Stored with a bias of 127. The actual exponent is `E - 127`.</li>
        <li><b>Fraction (F):</b> 23 bits (Bits 22-0). Represents the fractional part of the mantissa.</li>
      </ul>

      <div class="diagram" id="diagram-ieee754-format">
        <img src="assets/ieee754_format.png"
          alt="IEEE-754 32-bit floating point format showing sign, exponent, and fraction fields"
          onerror="this.parentElement.innerHTML='<div class=\'placeholder\'>[IEEE-754 Format Diagram - Image: assets/ieee754_format.png]</div>'">
      </div>

      <p>For <i>normalized</i> numbers, the standard assumes a hidden "1" before the binary point of the fraction. Thus,
        the complete mantissa is `1.F`.</p>
      <p>The value (V) of a normalized number is given by:</p>
      <p class="formula"><i>V = (-1)<sup>S</sup> × 2<sup>(E-127)</sup> × (1.F)</i></p>

      <p>The standard also defines several special cases, which our design must handle:</p>
      <ul>
        <li><b>Zero:</b> When `E = 0` (all zeros) and `F = 0` (all zeros). The sign bit can be 0 or 1, representing +0
          and -0.</li>
        <li><b>Infinity (Inf):</b> When `E = 255` (all ones) and `F = 0` (all zeros). This represents overflow or
          division by zero.</li>
        <li><b>Not-a-Number (NaN):</b> When `E = 255` (all ones) and `F ≠ 0` (non-zero). This represents the result of
          invalid operations, such as `0/0` or `Inf × 0`.</li>
        <li><b>Denormalized Numbers:</b> When `E = 0` and `F ≠ 0`. These represent very small numbers. Our design treats
          denormalized inputs as zero, which is a common simplification in high-speed multipliers.</li>
      </ul>

      <h3>4. Proposed Architecture</h3>
      <p>The proposed floating-point multiplier implements the multiplication of two 32-bit IEEE-754 numbers, `A` and
        `B`, to produce a 32-bit result, `Y`.</p>

      <div class="diagram" id="diagram-proposed-architecture">
        <img src="assets/proposed_architecture.png"
          alt="Block diagram of the proposed floating point multiplier architecture"
          onerror="this.parentElement.innerHTML='<div class=\'placeholder\'>[Proposed Architecture Diagram - Image: assets/proposed_architecture.png]</div>'">
      </div>

      <p>The overall architecture is partitioned into several key functional units, which are mapped into a two-stage
        pipeline:</p>
      <ol>
        <li><b>Field Extractor:</b> In Stage 1, the 32-bit inputs `A` and `B` are deconstructed into their respective
          Sign (`S_a`, `S_b`), Exponent (`E_a`, `E_b`), and Fraction (`F_a`, `F_b`) fields.</li>
        <li><b>Special Case Detector:</b> Parallel logic checks the exponent and fraction fields of both inputs to flag
          any Zero, Infinity, or NaN conditions.</li>
        <li><b>Sign Calculator:</b> The resultant sign (`S_y`) is computed by a simple XOR of the input signs: `S_y =
          S_a ⊕ S_b`.</li>
        <li><b>Exponent Adder:</b> This unit calculates the new exponent. It sums the two 8-bit exponents and subtracts
          the bias (127): `E_y = E_a + E_b - 127`. This raw sum is later adjusted during normalization.</li>
        <li><b>Vedic Mantissa Multiplier:</b> This is the core of the design. It takes the 23-bit fractions `F_a` and
          `F_b`, prepends the hidden "1" to create two 24-bit mantissas (`M_a = {1, F_a}` and `M_b = {1, F_b}`), and
          multiplies them. This is done by the `vedic24x24` module, which produces a 48-bit product `P_m`.</li>
        <li><b>Normalizer & Selector (Stage 2):</b> This unit takes the intermediate results (S_y, E_y, P_m) and the
          special case flags from Stage 1. It performs two main tasks:
          <ul>
            <li><b>Priority Selection:</b> It checks the special case flags. If a NaN, Inf, or Zero condition is met, it
              forces the output to the correct IEEE-754 representation for that case (e.g., `32'h7FC00000` for NaN).
            </li>
            <li><b>Normalization:</b> For a normal multiplication, the 48-bit product `P_m` must be normalized. The
              product `M_a × M_b` will be between 1.0 and ~4.0. If the MSB of the product (`P_m[47]`) is `1`, the
              product is in the range [2.0, 4.0). The mantissa is taken from `P_m[46:24]` and the exponent `E_y` is
              incremented by 1. If the MSB (`P_m[47]`) is `0`, the product is in the range [1.0, 2.0). The mantissa is
              taken from `P_m[45:23]` and the exponent is unchanged.</li>
            <li>It also checks for <b>Overflow</b> (final exponent > 254) and <b>Underflow</b> (final exponent <= 0),
                setting the result to Inf or Zero, respectively.</li>
          </ul>
        </li>
        <li><b>Output Assembler:</b> The final selected Sign, Exponent, and Mantissa are concatenated to form the 32-bit
          output `Y`.</li>
      </ol>

      <h3>5. Pipeline Architecture</h3>
      <p>To achieve high throughput, the design is partitioned into a two-stage pipeline, separated by a bank of
        registers. This allows the multiplier to begin calculating a new result while the previous result is in its
        final stage. The `valid_in` and `valid_out` signals manage the data flow.</p>

      <div class="diagram" id="diagram-pipeline-architecture">
        <img src="assets/pipeline_architecture.png" alt="Pipeline architecture diagram showing Stage 1 and Stage 2"
          onerror="this.parentElement.innerHTML='<div class=\'placeholder\'>[Pipeline Architecture Diagram - Image: assets/pipeline_architecture.png]</div>'">
      </div>

      <h4>Stage 1: Multiply and Add</h4>
      <p>This stage contains the most computationally intensive logic. It performs the parallel multiplication of the
        mantissas and the addition of the exponents.</p>
      <ul>
        <li><b>Inputs:</b> `clk`, `rstn`, `a`, `b`, `valid_in`.</li>
        <li><b>Registers:</b> `a_r`, `b_r`, `valid_r`.</li>
        <li><b>Combinational Logic:</b>
          <ol>
            <li>Inputs `a` and `b` are latched into `a_r` and `b_r`.</li>
            <li>Fields are extracted from `a_r` and `b_r`.</li>
            <li>All special case flags (`a_is_zero`, `b_is_inf`, `a_is_nan`, etc.) are computed.</li>
            <li>The 24-bit mantissas (`man_a`, `man_b`) are formed.</li>
            <li>The `vedic24x24` module runs, producing the 48-bit `man_prod`.</li>
            <li>The exponents are added (`exp_sum = exp_a + exp_b`).</li>
            <li>The preliminary normalization logic (checking `msb_prod`, selecting `mant_trunc`, and calculating
              `exp_unbiased_signed`) is performed.</li>
          </ol>
        </li>
        <li><b>Pipeline Registers (Output):</b> At the next positive clock edge, all intermediate results are latched
          into the Stage 2 registers:
          <ul>
            <li>`mant_r` (23 bits)</li>
            <li>`expu_r` (10 bits)</li>
            <li>`sign_r_r` (1 bit)</li>
            <li>All special case flags (e.g., `a_zero_r`, `b_nan_r`)</li>
            <li>`valid_stage1` (from `valid_r`)</li>
          </ul>
        </li>
      </ul>

      <h4>Stage 2: Normalize, Select, and Finalize</h4>
      <p>This stage operates on the stable outputs from the Stage 1 pipeline registers. It is a large priority-based
        selection logic.</p>
      <ul>
        <li><b>Inputs:</b> All registered signals from Stage 1.</li>
        <li><b>Combinational Logic (`always @*` block):</b>
          <ol>
            <li>A priority multiplexer selects the final output `y_next`.</li>
            <li><b>Highest Priority (NaN):</b> If `a_nan_r` or `b_nan_r` is true, or if `Inf * 0`, `y_next` is set to
              the quiet NaN representation (`32'h7FC00000`).</li>
            <li><b>Next Priority (Infinity):</b> If `a_inf_r` or `b_inf_r` is true (and not a NaN case), `y_next` is set
              to Infinity (`{sign_r_r, 8'hFF, 23'd0}`).</li>
            <li><b>Next Priority (Zero):</b> If `a_zero_r` or `b_zero_r` is true (and not a NaN case), `y_next` is set
              to Zero (`{sign_r_r, 8'd0, 23'd0}`).</li>
            <li><b>Lowest Priority (Normal Calculation):</b>
              <ul>
                <li>The registered exponent `expu_r` (now `exp_s`) is checked.</li>
                <li>If `exp_s > 254` (Overflow), `y_next` is set to Inf.</li>
                <li>If `exp_s <= 0` (Underflow), `y_next` is set to Zero.</li>
                <li>Otherwise, the final result is assembled: `y_next = {sign_r_r, exp_s[7:0], mant_r}`.</li>
              </ul>
            </li>
          </ol>
        </li>
        <li><b>Output Registers:</b> The final `y_next` and `valid_next` are registered at the module's output ports,
          `y` and `valid_out`, to ensure a clean, synchronous output.</li>
      </ul>

      <h3>6. Vedic Mantissa Multiplier</h3>
      <p>The core of our design's performance and structural regularity comes from the 24×24 mantissa multiplier, which
        is built using the principles of Vedic mathematics.</p>

      <h4>Urdhva-Tiryagbhyam (Vertically & Crosswise)</h4>
      <p>This sutra provides a general "divide and conquer" algorithm for multiplication. To multiply two N-bit numbers,
        we split them into two N/2-bit halves:</p>
      <ul>
        <li>`A = A_hi | A_lo`</li>
        <li>`B = B_hi | B_lo`</li>
      </ul>
      <p>The product `P = A × B` is then calculated in four parallel steps:</p>
      <ol>
        <li>`P0 = A_lo × B_lo` (low × low)</li>
        <li>`P1 = A_lo × B_hi` (low × high)</li>
        <li>`P2 = A_hi × B_lo` (high × low)</li>
        <li>`P3 = A_hi × B_hi` (high × high)</li>
      </ol>
      <p>These four partial products are then summed with appropriate bit-shifts to produce the final 2N-bit result:</p>
      <p class="formula"><i>P = (P3 &lt;&lt; N) + ((P1 + P2) &lt;&lt; (N/2)) + P0</i></p>

      <h4>Hierarchical Architecture</h4>
      <p>Our design applies this principle recursively to build the 24×24 multiplier.</p>

      <!-- <div class="diagram" id="diagram-vedic-hierarchy">
        <img src="assets/vedic_hierarchy.png" alt="Hierarchical structure of Vedic multiplier from 3x3 to 24x24"
          onerror="this.parentElement.innerHTML='<div class=\'placeholder\'>[Vedic Multiplier Hierarchy Diagram - Image: assets/vedic_hierarchy.png]</div>'">
      </div> -->

      <ol>
        <li><b>Base Case: 3×3 Multiplier (`vedic3x3`)</b><br>This is the fundamental block. It takes two 3-bit inputs
          and generates a 6-bit product. This is implemented as a small combinational block using the Urdhva-Tiryagbhyam
          partial-product method.</li>
        <li><b>6×6 Multiplier (`vedic6x6`)</b><br>This module is constructed from four `vedic3x3` instances. It splits
          the 6-bit inputs `a` and `b` into 3-bit high/low halves (`a_hi`, `a_lo`, `b_hi`, `b_lo`). It then computes the
          four partial products and sums them with 3-bit and 6-bit shifts.</li>
        <li><b>12×12 Multiplier (`vedic12x12`)</b><br>Following the same pattern, this module uses four `vedic6x6`
          instances. It splits the 12-bit inputs into 6-bit halves and combines the results with 6-bit and 12-bit
          shifts.</li>
        <li><b>24×24 Multiplier (`vedic24x24`)</b><br>This is the final module used by the FPU. It instantiates four
          `vedic12x12` multipliers. It splits the 24-bit mantissas into 12-bit halves and combines the four 24-bit
          partial products with 12-bit and 24-bit shifts using a simple adder tree to produce the final 48-bit result.
        </li>
      </ol>
      <p>This hierarchical structure is highly regular, which simplifies design, verification, and physical layout on an
        FPGA, reducing routing congestion.</p>

      <h3>7. Implementation in Verilog HDL</h3>
      <p>The entire design was implemented in synthesizable Verilog HDL, following a modular, hierarchical approach.</p>
      <ul>
        <li><b>`fp_mul_pipelined.v` (TOP):</b> This is the top-level module that instantiates all other components. It
          defines the two-stage pipeline, including the main pipeline registers (`mant_r`, `expu_r`, etc.) and the
          Stage-2 combinational logic for normalization and special case selection.</li>
        <li><b>`vedic24x24.v`:</b> This module implements the 24-bit unsigned multiplication. It instantiates four
          `vedic12x12` modules and contains the adders required to sum the four shifted partial products.</li>
        <li><b>`vedic12x12.v`:</b> This module implements the 12-bit unsigned multiplication using four `vedic6x6`
          instances and their corresponding adders.</li>
        <li><b>`vedic6x6.v`:</b> This module implements the 6-bit unsigned multiplication using four `vedic3x3`
          instances.</li>
        <li><b>`vedic3x3.v`:</b> This is the base-case 3-bit unsigned multiplier.</li>
        <li><b>`tb_fp_mul_pipelined.v`:</b> A comprehensive testbench was created to verify the design. It generates a
          100 MHz clock and defines a task `apply_input` to feed test vectors to the multiplier and wait for the
          `valid_out` signal, checking the result.</li>
      </ul>
      <p>This modularity allows for each component of the Vedic multiplier to be tested and verified independently
        before being integrated into the main FPU datapath.</p>

      <div class="schematic-section">
        <h3>8. Schematic Overview</h3>
        <p>After the Verilog HDL code was synthesized using the Vivado Design Suite, a Register-Transfer Level (RTL)
          schematic was generated. This schematic provides a visual representation of the hardware architecture.</p>

        <div class="diagram" id="diagram-rtl-schematic">
          <img src="assets/rtl_schematic.png" alt="Register Transfer Level schematic from Vivado synthesis"
            onerror="this.parentElement.innerHTML='<div class=\'placeholder\'>[RTL Schematic Diagram - Image: assets/rtl_schematic.png]</div>'">
        </div>

        <p>The schematic clearly shows the two-stage pipelined architecture. The first stage (left) consists of the
          input
          registers and the large block of combinational logic corresponding to the `vedic24x24` multiplier and the
          exponent adder. A clear bank of flip-flops (the pipeline registers) separates the two stages. The second stage
          (right) consists of the large multiplexer network that implements the priority logic for selecting NaN, Inf,
          Zero, or the normalized result, along with the final output registers. The hierarchical nature of the
          `vedic24x24` module is visible, with the schematic showing the nested `vedic12x12`, `vedic6x6`, and `vedic3x3`
          blocks.</p>
      </div>

      <h3>9. Simulation and Waveform Analysis</h3>
      <p>The design was functionally verified by simulating the `tb_fp_mul_pipelined` testbench in the Vivado simulator.
        The testbench was designed to cover normal operation as well as all special cases defined by the IEEE-754
        standard.</p>
      <p>The testbench generates a 100 MHz clock (10 ns period). The `apply_input` task asserts `valid_in` for one
        cycle. Due to the two-stage pipeline, the corresponding `valid_out` signal is expected to go high <i>two</i>
        clock cycles later.</p>

      <h4>Case 1: Normal Operation (3.5 × -2.0)</h4>
      <ul>
        <li><b>Input A:</b> `3.5` = `32'h40600000`</li>
        <li><b>Input B:</b> `-2.0` = `32'hC0000000`</li>
        <li><b>Expected Y:</b> `-7.0` = `32'hC0E00000`</li>
      </ul>
      <div class="diagram" id="diagram-waveform-normal">
        <img src="assets/waveform_normal.png" alt="Simulation waveform for normal multiplication (3.5 × -2.0)"
          onerror="this.parentElement.innerHTML='<div class=\'placeholder\'>[Normal Operation Waveform - Image: assets/waveform_normal.png]</div>'">
      </div>
      <p>The waveform shows the inputs `a` and `b` being applied. Two clock cycles later, the output `y` correctly
        settles to `C0E00000` and `valid_out` pulses high for one cycle, confirming the correct result and pipeline
        latency.</p>

      <h4>Case 2: Zero Handling (0 × 5.0)</h4>
      <ul>
        <li><b>Input A:</b> `0.0` = `32'h00000000`</li>
        <li><b>Input B:</b> `5.0` = `32'h40A00000`</li>
        <li><b>Expected Y:</b> `0.0` = `32'h00000000`</li>
      </ul>
      <div class="diagram" id="diagram-waveform-zero">
        <img src="assets/waveform_zero.png" alt="Simulation waveform for zero multiplication (0 × 5.0)"
          onerror="this.parentElement.innerHTML='<div class=\'placeholder\'>[Zero Handling Waveform - Image: assets/waveform_zero.png]</div>'">
      </div>
      <p>As seen in the simulation, the special case logic in Stage 1 detects the zero input. In Stage 2, the priority
        selector multiplexes the correct zero representation (`32'h00000000`) to the output.</p>

      <h4>Case 3: NaN Handling (NaN × 2.0)</h4>
      <ul>
        <li><b>Input A:</b> `NaN` = `32'h7FC00001` (E=all 1s, F!=0)</li>
        <li><b>Input B:</b> `2.0` = `32'h40000000`</li>
        <li><b>Expected Y:</b> `NaN` = `32'h7FC00000` (Quiet NaN)</li>
      </ul>
      <div class="diagram" id="diagram-waveform-nan">
        <img src="assets/waveform_nan.png" alt="Simulation waveform for NaN multiplication"
          onerror="this.parentElement.innerHTML='<div class=\'placeholder\'>[NaN Handling Waveform - Image: assets/waveform_nan.png]</div>'">
      </div>
      <p>The waveform confirms that as soon as the NaN input is detected, the NaN logic takes highest priority. The
        output `y` is forced to `7FC00000`, which is the canonical quiet NaN representation hardcoded in our design,
        propagating the NaN state as required by the standard. Infinity Handling (Inf × 2.0) and the (Inf × 0) cases
        were also tested and produced the correct `+Inf` and `NaN` outputs, respectively.</p>

      <h3>10. Results</h3>
      <p>The project successfully yielded a functionally correct 32-bit floating-point multiplier. The results are
        summarized in two categories:</p>
      <p><b>1. Functional Verification:</b><br>
        The simulation results confirm that the designed multiplier is 100% logically correct for all tested cases.
      <ul>
        <li><b>Normal Multiplication:</b> Products are accurate.</li>
        <li><b>Pipeline:</b> A 2-cycle latency and 1-cycle throughput are confirmed.</li>
        <li><b>Special Cases:</b> Zero, Infinity, and NaN inputs are handled correctly according to IEEE-754 rules.</li>
        <li><b>Exception Handling:</b> Overflow cases correctly result in Infinity. Underflow cases correctly result in
          Zero. The `Inf × 0` case correctly produces NaN.</li>
      </ul>
      </p>
      <p><b>2. Synthesis and Performance (Analysis):</b><br>
        While a full physical implementation was not the primary goal, a synthesis of the design in Vivado provides key
        insights:
      <ul>
        <li><b>Area/Resource Utilization:</b> The Vedic multiplier's regular, hierarchical structure is highly amenable
          to FPGA logic fabric. The design synthesizes to a combination of Look-Up Tables (LUTs) and Flip-Flops (for
          pipeline registers).</li>
        <li><b>Timing/Performance:</b> The 2-stage pipeline successfully breaks the critical path. The maximum operating
          frequency (Fmax) is determined by the delay of Stage 1, which is significantly faster than a non-pipelined
          version.</li>
        <li><b>Throughput:</b> The design achieves a peak throughput of one multiplication per clock cycle, making it
          ideal for applications requiring a continuous stream of calculations, such as in FIR filters or matrix
          multiplication engines.</li>
      </ul>
      </p>

      <h3>11. Conclusion</h3>
      <p>This project has successfully demonstrated the design, implementation, and verification of a high-speed,
        two-stage pipelined IEEE-754 single-precision floating-point multiplier.</p>
      <p>The key achievement of this work is the novel and effective use of a <b>hierarchical 24×24 Vedic multiplier</b>
        based on the Urdhva-Tiryagbhyam sutra for the mantissa calculation. This approach was shown to be highly
        effective, creating a parallel and regular hardware structure that is efficient for VLSI implementation.</p>
      <p>The two-stage pipelined architecture successfully increases the throughput of the multiplier, making it capable
        of handling high-speed data streams. The Verilog HDL implementation was comprehensively simulated and verified
        in the Vivado Design Suite, proving its functional correctness. The design robustly handles all special cases,
        including Zero, Infinity, and NaN, as well as overflow and underflow conditions, ensuring full compliance with
        the IEEE-754 standard.</p>
      <p>This project validates that the fusion of ancient mathematical algorithms with modern digital design principles
        (like pipelining) can yield high-performance, efficient, and scalable arithmetic circuits suitable for modern
        FPGAs.</p>

      <h3>12. Future Scope</h3>
      <p>This project lays a strong foundation for several future enhancements:</p>
      <ol>
        <li><b>Double Precision:</b> The architecture can be extended to support the 64-bit double-precision format.
          This would primarily involve scaling the Vedic multiplier to a 53×53 hierarchy and expanding the exponent path
          to 11 bits.</li>
        <li><b>Advanced Rounding:</b> The current design uses truncation (round-to-zero). This could be replaced with
          more complex rounding modes specified by the standard, such as "round-to-nearest-even."</li>
        <li><b>Denormalized Numbers:</b> The multiplier could be enhanced to provide full support for denormalized
          (subnormal) input operands and results, which are currently flushed to zero.</li>
        <li><b>Deeper Pipelining:</b> To achieve even higher clock frequencies, the design could be partitioned into a
          deeper pipeline (e.g., 3 or 4 stages) by placing registers within the adder tree of the `vedic24x24` module.
        </li>
        <li><b>ASIC Implementation:</b> The Verilog design can be synthesized for an ASIC (Application-Specific
          Integrated Circuit) process to perform a detailed analysis of its power consumption, area, and timing.</li>
      </ol>

      <h3>13. Acknowledgment</h3>
      <p>We would like to express our sincere gratitude to our project supervisor, <b>Prof. P. Venkateshwaran</b>, for
        his invaluable guidance, continuous support, and insightful feedback throughout this project. His expertise in
        digital design and VLSI systems proved instrumental in shaping the direction of this research and refining our
        approach to the hierarchical multiplier architecture. His encouragement to explore unconventional methods, such
        as the application of Vedic mathematics to modern hardware design, broadened our perspective and strengthened
        the innovation in this work.</p>
      <p>We extend our appreciation to the <b>Department of Electronics and Telecommunication Engineering</b> at
        <b>Jadavpur University</b> for providing access to state-of-the-art laboratory facilities, software tools
        including Xilinx Vivado Design Suite, and a conducive academic environment that enabled us to complete this
        work. The department's emphasis on research-driven learning and hands-on experimentation was crucial to the
        successful completion of this project.
      </p>
      <p>We are also grateful to our peers and fellow researchers in the department for their constructive discussions,
        suggestions, and collaborative spirit during the course of this project. Special thanks to the faculty members
        who provided valuable insights during our interim presentations and helped us identify potential improvements in
        our design methodology.</p>
      <p>Finally, we acknowledge the contributions of the global research community whose published works in the field of
        floating-point arithmetic, Vedic mathematics, and VLSI design served as the foundation for this study. The
        open-access nature of academic literature and the spirit of knowledge sharing enabled us to build upon existing
        research and contribute our findings to this evolving field.</p>

      <h3>14. Author Contributions</h3>
      <p>This research represents a collaborative effort with distinct contributions from each author, while maintaining
        shared responsibility for the overall project outcomes.</p>
      <p><b>Krishnarjun Mitra</b> served as the principal architect and implementer of the floating-point multiplier
        system. His responsibilities included:</p>
      <ul>
        <li>Complete design and implementation of the two-stage pipelined floating-point multiplier architecture in
          Verilog HDL</li>
        <li>Development of the hierarchical Vedic multiplier modules (3×3, 6×6, 12×12, and 24×24) based on the
          Urdhva-Tiryagbhyam sutra</li>
        <li>Design and coding of all special case handling logic for Zero, Infinity, NaN, overflow, and underflow
          conditions</li>
        <li>Creation of the comprehensive testbench environment and execution of functional verification simulations in
          Vivado</li>
        <li>Synthesis and timing analysis of the design, including RTL schematic generation and resource utilization
          assessment</li>
        <li>Preparation of all technical documentation, including this manuscript, diagrams, waveform analysis, and code
          commentary</li>
        <li>Development of the project website, integration of interactive elements, and establishment of online
          accessibility</li>
      </ul>
      <p><b>Souvik Das</b> contributed significantly to the theoretical foundation and validation of the project through:
      </p>
      <ul>
        <li>Comprehensive literature review and comparative analysis of existing floating-point multiplier architectures
        </li>
        <li>Theoretical study of Vedic mathematics principles and their applicability to digital circuit design</li>
        <li>Conceptual discussions on architectural choices, pipeline depth optimization, and design trade-offs</li>
        <li>Critical review and validation of simulation results against IEEE-754 standard specifications</li>
        <li>Manuscript proofreading, formatting, and technical accuracy verification</li>
        <li>Assistance in preparation of presentations and documentation of comparative performance metrics</li>
      </ul>
      <p>Both authors participated equally in project planning, weekly progress reviews, problem-solving discussions, and
        the formulation of conclusions and future scope. All design decisions were made collaboratively, ensuring that
        the final implementation reflects a unified vision and balanced approach to the research objectives.</p>

      <h3>15. References</h3>
      <p>[1] M. S. H. Hemant and N. Raghuwanshi, "VLSI design and analysis of IEEE 754 Floating Point Multiplier,"
        <i>International Journal of Science, Engineering and Technology (IJSET)</i>, vol. 10, no. 2, 2022.
      </p>
      <p>[2] H. Ghabeli, "Design of Floating-Point Multiplier Architecture with Adaptive Data Timing Channels," <i>2024
          6th Iranian International Conference on Microelectronics (IICM)</i>, 2024.</p>
      <p>[3] N. Bai, H. Li, J. Lv, S. Yang, and Y. Xu, "Logic Design and Power Optimization of Floating-Point
        Multipliers," <i>Computational Intelligence and Neuroscience</i>, vol. 2022, Article ID 6949846, 2022.</p>
      <p>[4] S. Havaldar and K. S. Gurumurthy, "Design Of Vedic IEEE 754 Floating Point Multiplier," <i>2016 IEEE
          International Conference On Recent Trends In Electronics Information Communication Technology (RTEICT)</i>,
        May 20-21, 2016, India.</p>
      <p>[5] IEEE, <i>IEEE Standard for Floating-Point Arithmetic</i>, IEEE 754-2019, 2019.</p>

    </div>
  </div>

  <footer class="site-footer">
    <div class="footer-content">
      <p class="footer-author">Created and maintained by <strong>Krishnarjun Mitra</strong></p>
      <p class="footer-affiliation">Department of Electronics and Telecommunication Engineering, Jadavpur University</p>
      <p class="footer-copyright">&copy; 2025 Krishnarjun Mitra. All rights reserved.</p>
    </div>
  </footer>

  <div class="read-progress" role="progressbar" aria-label="Reading progress">
    <div class="read-progress__bar" id="readProgressBar"></div>
  </div>
  <div class="read-progress__label" id="readProgressLabel">0% • 100% left</div>
  <div class="fab-container" aria-label="Quick actions">
    <button class="fab" onclick="downloadPDF()" title="Download PDF" aria-label="Download PDF">
      <svg width="28" height="28" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
        <path d="M12 3v12m0 0l-5-5m5 5l5-5" />
        <path d="M5 19h14" />
      </svg>

    </button>
    <button class="fab" onclick="triggerPrint()" title="Print" aria-label="Print">
      <svg viewBox="0 0 24 24" role="img" aria-hidden="true">
        <path
          d="M6 9V2h12v7h2c1.1 0 2 .9 2 2v6h-4v3H6v-3H2v-6c0-1.1.9-2 2-2h2zm2-5v5h8V4H8zm8 14H8v1h8v-1zm4-4v-4H4v4h16z" />
      </svg>
    </button>
  </div>
</body>

</html>